---
link: https://www.youtube.com/watch?v=Ij0dRKiO_Hw
dc-link: "[[tóm tắt khoá học về Make]]"
---

hey everyone I'm Ben and in this video I'll give you the most comprehensive make.com course on the internet I'll cover from beginning to end everything you actually need to know for building and selling automations on make.com from the foundations to all the important built-in modules AI integration and more advanced features like apis HTTP requests scraping text parsing and formulas and I'll make it all practical by giving you plenty of examples if you don't know me yet I'm Ben I run an AI automation agency since 2023 and I've built delivered hundreds of make.com automations uh for clients by now and this video is a breakdown of everything I know and by the end of this video you should understand everything you need to know to start building or selling automations on make.com now before starting very quickly what are we going to cover as I said we're going to cover everything from beginner to Advanced uh and basically you're going to learn everything you need to know to build any automation on make.com now if you have a little bit of experience with make.com you already know some things you can also use the chapters below to go to the section that that that's most interesting to you so what are we going to cover first I'm going to give you a quick overview of make.com why use it uh the key Concepts and a little bit of an overview of the UI uh then I'll cover uh data types now uh this is where most non-technical people uh get scared uh and you don't actually need it uh to understand this 100% to actually start building on make.com but in my opinion it is extremely important to actually understand how these data types and structures actually work because first of all every everything you're going to do in make.com will make so much more sense if you understand these data structures second of all debugging which is a part of building AI automations or automations in general will become 10 times easier because most errors and problems you'll face are usually related to data types and data structures and thirdly it really is not rocket science so please stick with me uh for that one if you're not familiar with it yet because I think it's going to help you a lot in the long run and you learn it once and you'll know it forever then thirdly I'll go over all the Essen modules and skills you need to know in make.com triggers web hook filters routers connections uh HTTP requests iterators aggregators tools and error handlers uh then I'll go over uh AI integration right how do you actually integrate AI into these workflows right how do you set up these AI modules how do you uh prompt them the types of N&M to use the prompting Frameworks to use uh how to use prompt chaining and use cases for AI integration into these workflow automations and uh lastly I'll go over some Advanced features which you might need in more uh more complex automations like functions text parsers regexs and some more and then lastly I'll build a lead generation automation from scratch which I think can give you a good idea on how to approach building uh your own automations and I'll give plenty of examples while explaining all of these Concepts so what is make.com make.com is a no code automation platform uh which we can use to automate uh tasks and workflows across thousands of different uh softwares now this has existed for quite a while already uh but now that we have ai these softwares became 10 to 100 times more powerful because with AI we can do uh we can automate more complex processes and do lots more advanced uh automation for example uh a traditionally common used automation before the AI era was like a lead filled out a lead form and it automatically updates into your CR but now that we have ai we can do lots more complex things with that data right for example we can first research the lead uh then we can let an AI or an N&M mod module uh actually qualify the lead and we can add in the all the enriched data into the CRM and actually already have pre-qualified the lead now make.com has a really easy drag and drop interface and lots of these uh modules built in to easily work with different data types and different data structures now why do we use make.com of course again to automate tasks and workflows across thousands of different softwares make.com has lots of native Integrations with most uh popular softwares making it a lot easier for us to connect to different softwares without custom apis now we can use that of course to automate lots of business processes to make businesses more efficient and now that AI has put automation on steroids uh automation is really going to be one of the fundamental pillars uh for businesses in the upcoming years to stay competitive and efficient in the marketplace and therefore uh people who provide these services to companies have lots of opportunities to to make money right uh some examples of automations we use uh in our business for example are automating newsletters social media content generation inbound lead qualification uh personalized outbound email campaigns uh but we do lots more and in today's age with AI you can really automate almost any process or workflow you can think of now very quickly before diving into make.com how does make.com compare to other no code automation softwares zapier is probably the most famous one and NAD is getting a lot of traction too at the moment and basically the way we can see it here is on the left side with zapier it's generally the easiest to use platform and on the right side we have the more technical uh platform with NAD Now make.com sort of lies in the middle now it's important to note that usually the easier to use a platform is the less customization and flexibility we'll have in the long run or for more complex workflows and second of all they're usually more costy right or pricey right while the technical ones we have more customization and flexibility uh for for complex workflows and generally there are cheap to one right make.com lies in the middle but I'd say lies a little bit more towards n8n side especially in terms of price and customization so my general recommendation for non technical people starting with automation is make.com because it's uh very easy to use but we're not limited uh by by flexibility we can still do very custom and complex uh workflow Automation and it's also very cheap to run compared to a platform like zapier now naden could be another option but naden might have a little bit of a steeper learning curve when you're just starting out as it is a bit more technical right uh you can see also that make.com has more than 2,000 native Integrations basically allow us to connect to softwares with one click instead of setting up custom apis which can be a little bit trickier when you're just starting out right so this this really helps a lot making it easy so some key Concepts or terminology you need to know in make.com is first of all scenarios scenarios are just the name make.com gives for one workflow or one automation uh system right then we have modules which is one step of the scenario right and a module can be an API a software a data transformation module it's just one of the the modules in a scenario then we have connections which is connections with softwares right then we have web hook and web Hooks and triggers and web Hooks and triggers are the only two ways to activate or trigger an automation or a workflow and then we have operations and operations is basically one run of one module right and it's important to understand that terminology because we get charged based on operations in make.com so let me dive into make.com uh and give you a little bit of an overview of make.com so uh first of all here we have make.com uh you can sign up for a free account here now it's pretty straightforward to sign up so I'm not going to bore you too much uh going through that process really easy once you've logged in you'll come to a screen like this where you have uh your dashboard overview now I'll not go over everything because first of all 95% you'll never use and second of all I want to keep this practical so really show you the actual important settings and and features here in make.com so first of all here we have the dashboard right where we get an overview of the operations we've run uh this month uh now in these tabs uh the only really important ones and the ones that you're going to use is uh maybe users where you can invite other members to your team right pretty straightforward you can just invite a new one through email uh then we have the subscription which is the paid plan now you can you can start for free right uh and you can have two active scenarios completely for free right now it's perfectly fine to start with and to try this out but the limitations of the free plan are that we can only have two active scenarios two active automations uh we have a five minute scenario execution time which can become a limitation very very quickly uh because as soon as an automation runs for longer than five minutes it will run into an error right and we have only have a 5 MB file size right these are the three main limitations of the free plan uh so as soon as you're going to take this a little bit more serious and start automating multiple projects or more more complex workflows uh you need to go to the pay plan now I recommend you go straight for the Pro Plan uh because with the Pro Plan you basically have zero limitations anymore right you can do anything uh in inside of the Pro Plan now I have it on 20,000 operations but if you're just starting you could probably go for the 10,000 which means it's $18 a month uh and you can do quite a lot as you can see here we did don't have really have limitations uh in because in the core plan we still have a 40 minute scenario execution time so if you have a workflow that runs for longer than 40 minutes it will time out and give you an error uh we only have 100 MB file size which usually should be enough uh but with the Pro Plan you don't have any of these limitations so I recommend going for this one if you're seriously going to build out automations for the team plan I haven't really found a good use case for the team plan as you can also invite members on the Pro Plan so that's it for the plans then here on the sidebar again you're not going to really use any of these except for scenarios right because these others I can walk you through very quickly the the templates is basically sort of a template library for make.com I can tell you they're very simple the templates and in practice they're not very usable uh then we have connections where we basically have a list of all the softwares we've integrated but we can do that inside of the scenarios right then we have web Hooks and we have some more options but again you're never going to spend any time here right or rarely so let me dive into this scenarios where you you're going to spend most of the time because here we're actually building our automations right as you can see I have all my automations listed here these are my active ones and uh here below you can see I have the non-active ones now I'm very disorganized as you can see but you can organize this a bit bit better in folders which is probably recommendable to do if you have this many automations now here we can create a new scenario but what I want to do first is show you uh an automation that I use and through that uh automation example I will go through all the important data types and structures which again are important to understand and all the important modules you should know in uh makom so let me show you an example of an automation that I use uh we can check the YouTube competitor tracker now as you can see here we have lots of different modules now what this uh automation does basically checks on a daily basis uh some YouTube channels active in the AI space to see if they have uploaded new videos and if they have uh we extract uh summaries uh from the transcripts and uh extract some other data points like views Etc and I'll put it back into my database now in this case I use air table so as you can see here in my air table I have the channel URLs that I want to track right and uh it outputs it back into that a table so I get a nice summary so I'm going to run this in a second so you get a better idea but very quickly if you're new to the make.com interface right as you can see we have the modules here we have lots of different modules here that's why I think it's a good example and I'm going to go through all of these modules in detail and all the other important modules uh later but first I want to just give you a quick overview of the settings here so as you can see this on the left side the air table which is the search record records module has one more Circle which is the trigger right and as you can see here we have the scheduling trigger so this automation runs every day at 9:00 a.m. right now here at the bottom we have the menu bar right and on the left side this button you're going to use quite a lot which is the Run ones where we can basically activate uh the automation manually and you're going to use this a lot to test out your your automations right then here we have another option to to define the trigger right then we have a save button here uh to save the workflow when you're building this one you're not really going to use in practice then we have some settings here now in the settings you're not really gonna touch this when you're building on on make.com except for this one the allow storing of incomplete executions now this this one uh we need to activate one when we are going to work with error handlers which is very important uh when we deliver this to clients Etc and when we run these automations at scale this is important but I'll get to that uh the error handlers later in this video then here we have notes so you can add some notes to the to workflow I never use it to be honest and then we have here previous version so you can undo your last actions and we have the auto align so let's say I'm building and I'm being messy uh make.com as a feature where we can Auto align right and here in the three buttons this one you won't really use the explain flow these two are important for example I'm going to uh give you this automation if you want to want to have it so I can just click here on export blueprint and basically what it will do is it will export a Json as you can see Json right and if you now want to import this automation or this flow into your make.com you can just in yourm make.com click on import blueprint right you choose that Json file and you'll have the whole automation workflow pasted into your uh make.com account so that's it here we have just the modules which again I'll go over later in this video uh but that's it really for the for the settings right so quite easy so let me just run it and walk you through very quickly so if I run it as you can see first here it's extracting all uh the Youtube channels I want to track right then we have the RSS feed which again I'm going to explain all of this in more detail later but this basically checks if they're if they've uploaded new videos and if they did we extract the video URL now this text parser will take the video ID which we need in this module uh which is an HTTP request which is basically a custom API call which scrapes the YouTube transcript of the video right now now these two modules basically transform the data we got from uh the Youtube transcript uh into a format that we then pass into the open AI module which basically makes a summary of YouTube transcript and then we output it back into air table together with some other data points like views Etc so we go back into air table if I go into the YouTube content tracker you can see we got new video summaries right of some competitors right so that's how it works in practice so now before I go into details and explain you all of these modules and how they work and all of the other important modules to know in uh make.com I do want to go over the data types and the data structures again not the most exciting topic but really really useful and it's going to help you so much understanding everything else ring in make.com if you understand the data types and the data structures and it's also going to help you debug so much faster so stick with me for 10 minutes because uh you learn this once and you'll know it forever so why are data types and data structures important to understand it's because when we're automating workflows like this we're basically uh passing data from one module or API or software to to another module right and each of these modules expects data to be structured in a specific way to be able to receive the data right and then outputs data in a specific uh structure too so it's really important to understand what a specific module what type of data a specific module expects right and the fortunate thing is make.com makes that really easy for us instead of showing us raw data or h us having to put in raw data they have an interface uh to make it really easy for us to understand so for example if we have this RSS feature right which basically checks uh YouTube channels to check if they have uploaded new videos we can see here we have the input Fields right so what does this uh module expect the data to be put in so here we have the URL which is the URL of the YouTube video in this case and we have a date and you can see here the type it expects is a date so we know that we have to fill in a date format right where we have a date two where we can basically filter right I'm going to go through all of these in more detail later but let's stick to to to input fields for now and then lastly we have uh a maximum number of returned results and you can see type is number so here we can only put in a number we cannot put in text Etc so make.com makes this really easy for us to understand what these modules expect now this one for example is a little bit more complicated right we need an array right which I'm going to again explain in a second uh but make.com just shows us very easily what data it expects right now now the second nice thing in make.com is here in these bubbles we basically can see the result right of uh this module running right so the output of this module and again make.com shows uh this in in an easy to read way right we don't have to look at Raw data we can sort of look at it in a in a way simpler way so we can see here the input data what did they receive and here we have the output data right and and instead of seeing raw data we have this sort of expandable little things so we can see we get all the data back we get a URL from a video the date created the author uh and then we get some other data points here right now in the Raw data this actually looks very different so if I go go here and download output bundles this is the actual raw data of that right which is a lot more complic that being said sometimes we have to transform data in order to be able to pass it on to the next module because the data structure we get from this output for example is different uh than what the next module expects right it's it's structured in a different way than the next module expects so for example we have that in this part and that's why we use some data transformation modules which again I'm going to explain in more detail later right but that's the second reason why it's really important and the third reason is sometimes we have to filter data or we have to Loop over data right basically meaning for example in this one uh we need this automation to run on 11 different YouTube channels right which are in our our database right we don't want to run it only on one right and sometimes we have to instruct the system to actually filter this out separate it and run it 11 times on each of these these modules and we can do that through iterators which I'm going to explain in a second too but it's important to understand data structures when you're going to work with iterators and aggregators and things like this now again nice thing make.com has a lot of these uh iterators and Etc built in for example here it automatically detected that there were 11 YouTube channels so you can see it automatically ran this 11 different times on each of the different YouTube channels now don't worry if you don't understand this completely yet uh I'm going to go over everything in more detail in this video so that being said this is why data and data structures are important to understand and it's going to help you a lot in the long run so what are the different data structures I'll go back to uh the presentation quickly so first we have strings right and strings are really easy it's basically just text right strings of characters for example names messages but anything really that that is uh text right and In The Raw data we can identify it through the double um quotation marks right so an example could be new age digital just the name of company right and in make.com we can recognize it because it says text right it expects text as you can see right so that's a string really easy now in the Raw data the way you can see that is through the through the quotation marks right then we know it's a string then we have numbers now numbers speak for themselves numerical values like ages ages budgets Etc now the difference is in the Raw data it's without quotation marks right it's just a number right now again we can identify this in make.com really easily because make.com just tells us right here type number so we can put in a name or anything else right so the way you can see this in uh the raw data for example if we go in that same one here we just get it presented in a nice way so there are no quotation marks for Strings Etc but if we look at the raw data we can see for example the URL is a string right and the Max results is five right we don't have the quotation marks uh now then we have uh dates which is just a specific input format that some apis or or modules expect right then we know we have to put in a specific date format which you can usually do like this or if it has to be time specific it's with an ISO formatted string I I call it which basically here says T which is time right with the hours minutes and seconds and even a time zone again we can easily recognize this uh in make.com uh because it just says date right same here date right now in make.com is really easy if we want we can just go to the date section and for example if you want a date of now we can just click it like this and make.com will automatically fill out today's date right but if not if you want to do a specific date you have to type it in to that specific format right now then we have bolans which are basically true or false conditions right and make.com they present it through a checkbox again making it really easy for us uh to do right so an example is true or false right so in make.com you will see this for example as just a check mark if we check this one all the way at the end here we have Smart links right and we see yes or no right and we can just select it but actually in the Raw data it will say true or false because that's how the software in this case expects the data to be received right so if we look at the raw data we can see false right and without quotation marks because it's a ban right then we have binary data uh which are for files or audio for example uh if we want to pass in a document to Google Drive uh then we would have to work with binary data now we don't have that in this example of this automation but again m.com makes this really easy for us uh because as soon as a modu expects um file or binary data it will automatically appear inside of make.com as a check mark it will automatically identify that one of the previous modules has binary data and then you can just select it like this right so again making it really easy for us now this is still straightforward I think in the next part is where most uh non-technical people uh throw in the towel so please stick with me because understanding this will help you a lot and really it's not rocket science so the next one is an array and an array you could basically just see as a list right a list of values for example right uh an example could be a list of emails right so inmate.com you can recognize it by seeing an input field for example domains in this case and you have different items and you you'll have this extra button with add item so we have three emails and you could basically see this as a spreadsheet with one column with a list of values right as you can see here now the way this uh shows in raw data is through these um square brackets right that's how you can identify that something is in Array right so we have these square brackets then we have um the value which in this case is a string that's why we have the quotation marks and they are separated all the values are separated by commas uh except for the last one where we don't need a comma so basically as soon as you see this you know that something is an array just a list now why are they important because lists store multiple values so because for example uh in in the example I showed we have a list of YouTube channels right and we want to retrieve the entire list right so the way we get that back from Air table is through an array right a list of all the YouTube channels right now the second which you've probably already heard is Json right which is also called an object right and in make.com they call it a bundle which I'm going to explain you in a second so a Json all it is is a structured way to store and transfer data and it's the most common way to send and retrieve data in in modern apis right literally 99% plus of apis use Json right so it's really important to understand Json and it's really again not rocket science right so the way you can see it is basically for example multiple data points for one person or product so instead of just a list of single values single emails we actually it's a it's a structured object with multiple data points on one person right so for example we have email name and Company right and the way that shows in uh the raw data is through the Curve cly brackets right as soon as you see these curly brackets with here we have the key and here we have the value right as soon as you see that you know we we are dealing with a Json right and it's basically just to store structured data right a way to store structured data that's all it is and again we separate the values through a comma except for the last one and again we have the quotation marks here because these are strings and you can basically see it like a spreadsheet with multiple columns right so we have the email name company right with the three values right so that's all Json is now we're almost there stick with me uh then we have array of objects which make.com calls a collection now you already know what an array is and you already know what an object is so an array of objects is basically a list of Json right so in our example in our previous example we had a person with multiple data points all an array of objects would be in this case is multiple persons with multiple data points right so as you can see here we have that same Json but in this case we also have the curly brackets because it's an array and we have two different uh people's data points right and again we separate that through a comma and we end it with the the square bracket so we can see this is an array this is a Json so it's multiple Json inside of an array so it's an array of objects and in make.com they also call that a collection now this can also be 10 or hundreds of different uh objects right so veryimportant to understand this is a collection right in inmate.com and one single one would be a bundle right now lastly you can think of this of course again as a spreadsheet with multiple columns right so instead of just one we have a list of multiple ones right and then we have the last last one really which is nested objects which is structured data inside of structured data right so for example in that same example we have right name Anna email and Company but inside of company we have another few data points so we have another Json inside of the Json right so it's structure data inside of the uh structured data right so for example the company name and the company industry right so we have a Json here right for the company and a Json for the person so it's a structured object inside of a structured object now this can be combined these arrays and objects can be can can be combined but once you understand arrays and objects or Json and and lists right you understand all these data structures right because sometimes you'll see things like this right you have an array right with multiple objects right but inside of the object we have another object and inside of the the the nested object we have another array another list now don't worry about actually having to make these these objects and these these things you you rarely ever have to write these yourselves but it's really important to understand the structure really if you understand arrays and you're going to make your life a lot easier as uh making automations right so knowing this let me show you an example so if we go back here to uh the automation right so as you can see here right in this first module where we search records where we basically retrieve all the records right you can see that here again we get make.com sort of nice little way to see what we get back so we you can see here we get multiple bundles right so we get the 11 bundles now and now you know what a bundle is Right a bundle is basically a Json right so each of the bundles is basically one one of the records right or rows in um in air table right and each of these bundles of course have multiple data points right the channel URL the videos the subscribers the channel ID and you'll see this in here if we open the bundle we can see we have the channel ID we have the YouTube the channel Subs the subscribers the videos Etc and you can see inside of this we have an array right so we have multiple data points inside of this now if we look at the raw data here we can see that it's an array right which a very long array which stores all these different records in Jon as you can see this is one record one row right and we basically get the list of all these rows now make.com automatically identifies right that these are different uh rows right so they automatically put it in a to a bundle here now why is that important because in make.com if make.com presents this like a bundle so these all these 11 different bundles if we pass in a specific value to uh the next module make automatically identifies and going to run this automation on each of the different bundles make the comics it really easy for us because instead of us having to uh separate all these little objects Etc we can just pass on a variable it auto automatically identified that that variable is available in all 11 bundles and it will run this module uh on all the different B bundles and as you can see it did it 11 times and that's why we see these 11 different operations because it basically ran 11 different times on 11 different values now this is all going to make a lot more sense uh when we're actually going to build and I'm going to get practical in just a second but the key takeaways is understand the different data structures especially understand what arrays and Json or objects are understand that bundles which are Json right are um processed separately in mate.com now knowing that everything else we're going to do and build it's going to be a lot more straightforward and uh simpler to understand so let's get a bit more practical and dive into the modules so let me dive back into the presentation so now I'll go over all the essential modules and scales uh that you need to know to build essentially any automation uh on mate.com right so I've covered all the important ones here uh so we go we'll go over native AP or connections how they call them in make.com variables triggers and web hooks uh filters and routers custom apis or HTTP requests uh scraping which um in practice you'll for any automation for most automation solution you need you'll usually need some uh type of scraping either web scraping or social media scraping Etc so it's very useful to to understand this then we go over iterators and aggregators some other built-in Tools in make.com that are uh practical to know and lastly error handlers then after this section we'll go into uh everything related to Ai and lastly at the end I'll cover some more advanced uh skills to know in make.com that uh become useful when you're building some more complex automation Solutions so let me dive back into make.com and explain uh these three right native apis variables and triggers and web hooks so if I back in make.com right and here I'm in the dashboard let's say we're going to create a new automation now all I do here is click on create a new scenario and what you'll see here is make.com automatically opens this which is basically all the different softwares make.com is natively integrated with right you can literally find thousands of softwares in here and most of the most popular ones are are here and all this is is basically make.com has set up a connection with these thirdparty softwares already for us so we don't have to set up custom API calls to these softwares making it a lot easier for us now the second thing make.com has done is basically has listed already the most common um API calls or actions we want to take uh inside of these softwares already for us so let's say we have uh Google Sheets here we already have all of these actions most common actions we actually want to take our building automations have they have already listed it out here right so you can see update a row bulk add rows search rows Etc right sales now how do we connect these uh it's usually either through an API key let's say with air table uh if we select SE search records for example if you don't have a connection yet it will ask you to add a connection right now let's say for air table we need to do it through an air table token uh or an API key normally right you and you can usually just find these inside of the software settings right and you select those you add those tokens in and then it's the connection is set up and the nice thing is that connection is set up forever right so as soon as you use a new action inside of air table you already have that connection set up now uh for for example with Google products it's even easier all we have to do is log some other softwares also have that so let's say we have the Google Sheets we want to add a row all you have to do here is sign in with Google right you have to give them the the permissions here that they can do anything and then you have it set up right so very straightforward now let's say uh which doesn't happen a lot but let's say you have an action that you want to take on on these softwares that is not yet listed here right so uh let's say I want to Archive a record right and it's not listed here but it is actually an action that is available inside of air tables API then that you usually find another option here at the bottom which is called other and it says make an API call and if you click this you see you actually need the endpoint the URL and we have to set up the the the specific action or API call we want to take on air table ourselves so you can go to the air table documentation and set this up yourself I'm going to explain later too how you set up custom apis but uh the nice thing at least with this is we already have the connection set up right so we don't have to add in API keys in this custom API request but if you don't find a specific action you want to take then it might be worth checking the documentation if that specific action is actually available in the API because then you could set it up uh through that this mod mod this this action make an API call right so the next thing we have to understand are triggers right and basically what you will see if you open one of these these softwares here right let's say air table the most common triggers are usually um listed here at the top right so the most common uh used sort of actions for uh the first step or the trigger are usually listed here above so we have watch records here returns all newly created or updated records uh or watch responses triggers when a new respones submitted or search record search for specific records right and you have the same in Google Sheets right watch new rows is at the top uh then we have for example here in cells watch changes uh sheets perform a function and you'll see that some of these for example this one is only available at this first step module so if we for example have it in the second right you will see that that one doesn't appear anymore right because it can only be used as a trigger right now there are two important things to understand with triggers is is we basically have two types of triggers right we have pulling triggers and we have instant triggers now what's the difference uh instant triggers basically does what it says it does it instantly triggers as soon as something happens in that software right so it automatically triggers the workflow or the automation as soon as something happens and only if something happens in that other software and pulling triggers are different because it doesn't uh instantly get triggered uh as soon as something is done it basically pulls the API or the software uh to check for update in a specific time interval so let's say every 15 minutes it will it will pull the API or the software to check if there are changes right and it's very important to understand the difference between these two because you might assume that for example this one watch records is instantly uh triggered as soon as let's say your watch record Returns on newly created or updated record so you might assume that this one is instantly triggered as soon as a new record is created but it's not and how can you recognize it in make it's simply because of this tag here instant right so you can see watch records doesn't have a tag instant so we know this is not an instant trigger this is a pulling trigger right so if I click this one for example watch records right so uh this is the nice thing of these connections right the air the the connection already identifies all my databases inside of my air table so let's say we have the B competitor watch table right we can select the table right away then we have the trigger field which is just uh will be used to sort the records right so it's only created ad and let's say we go with uh channel name and here we can Define the limit the amount of Records we want to return so in this case we're only doing 11 and these are optional fields which we don't really need right now so as you can see here this is uh we have a clock here and this basically tells us right away that this is a pulling trigger right this is not going to be instantly triggered with have to define the time interval in which we want um the trigger to pull for new updates right so if I click on save you can see it ask me choose where to start right so I can go from now on so any changes from now on uh will basically be returned right or we can choose all or it can choose from a specific day in the past or in the future or we can choose manually so let's say do we do from now on right and here if we click on here we can Define the time interval where how often we want to pull the API or the software to check for updates or changes right so we can go with regular intervals for example every five minutes or every one minute Etc uh now this is important to understand right it's every time we run this even though there were no updates in my airt or in my records it will still run every minute right and if you remember operations right we are charged for operations right and every time we run this even though though it doesn't return any results or there's no newly created row or updated row we'll still be running one operation per time right so it's a so you have do have to take that into account when you make these automations right now you can do every 50 minutes Etc now in our example we did every morning at 9:00 a.m. which is perfectly fine uh but for some automations you of course want to run this a lot more right so let's say every day at 9:00 a.m. right so here it asks you to activate the scenario I have to save it first right and now it basically pulls the API or air table every day at 9:00 am to check if there are new records or updated records right and it will retrieve it will output back those specific records now how do we test this we can test these workflows two times so we can either do this we're on once and you can see it basically returned nothing now why did it return nothing because of course between the time that I said from now on there were no updated or new records right so they basically no results but of course I can try and change it so for example here I can go choose where to start so let's say I just click all just to test it here you can also you can click run once or you can click run this module only which is useful when you have multiple modules and you don't want to run the entire thing for testing you only want to run a specific one so I click on run once now you can see we get all the 11 bundles back which are the 11 rows or records right with all the information now let's say we want an automation to happen instantly when something specific happens in another software right so with our table specifically we only have one option as you can see here we only have this one as an instant trigger which is watch responses triggers when a new response is submitted this basically for specific feature I think in air table which is air table forms um and you can see we only have this option for instant right so and the second thing you can see here is for all the instant ones we'll need web hooks now what are web hooks web hooks are basically a way where we can receive data from a third party software as soon as a specific action happens in that other software right so if I click here for example on ad and I created web hook you can see we get a web hook URL here from make.com which we can then give to that third party software in this case air table to basically uh tell a table send relevant information to this web hook as soon as something happens inside of air table now for this specific feature I think the the air table forms I've never worked with it but I can imagine in when you're creating a form you probably have an option there to add in a web hook right so you can just copy and paste that and then you know as soon as form is filled out the data will be sent to this module now in general you can see we're pretty limited with the amount of instant triggers we get right we can only do this one with our table for example with Google Sheets we only have watch changes in cells and perform a function but you will see that we're pretty limited let's say my CRM right we only have watch entries we're pretty limited so so let's say I wanted I want this automation to be triggered instantly when something happens in my in my my um air table dashboard so for example I want something instantly to happen when this check mark is checked right so how do I do that in make.com so that's where we can work with custom web hooks right which is a built-in module in make.com which you can find here or by just typing it in and basically we can create a custom web hook inside of make.com which we can then use inside of these other softwares to let them know that as soon as something happens there please send over data to uh my make.com scenario right so here you can go with custom web hook right and it works basically the same way you can see if I click on ADD here and for example call it uh aor table web hook and I click save again we get that URL right now every software will have a different way and sometimes there is not even a way uh but usually you can figure out a way to connect this web hook to that software to make sure that to instruct that software to send data to this web H so again that's all the webbook does right it instantly receives uh data as soon as something happens and only if something happens which makes it more efficient of course if we if we because it only runs when something specific happens we don't have to PLL every two three minutes be charge operations when something doesn't happen right now now I'm going to show you how to do this in air table because I do it a lot I'll show you one more example another example I commonly use a web hook for for example is my meeting transcript so what I I try to do with my meeting transcript is as soon as I finish a meeting I want the web hook to be triggered to get my transcript and then I can do things with it right I can update my uh CRM with sales call information or I can try to write social media content based on my transcript through AI Etc right so in this case I work with fireflies right now you'll see that fireflies has a native integration here with uh with make.com but they don't have any triggers and not any instant triggers so I created this web hook here what I can do is copy that we web hook and in fireflies it's quite simple if I go to uh fireflies if I go to settings you see here at the bottom that they actually give me an option for web hook right and some of these apps will have that available and we can just copy and paste it in and and you can see re receive real time not notifications with web web hook events right transcription completed and then we can add in that web hook and as soon as a transcript then is completed this make.com will be triggered and the transcript will be sent there right so that is how how uh web hooks work so let's say in my example again in air table we're going to set that up right so as soon as this is checked we want to retrieve the record right so how do we do this specifically in uh air table now you can skip this if you don't really work with air table but might still be useful so what we can do is we can set up an automation here so I'll just delete this one because I already had an automation set up uh but basically what we can do here is add a trigger now in this case when a record matches a condition of course when the check box is marked so we can just configure it here table uh now the sheet is channel the condition of course is when monitor is checked and then we have to add in specifically here in air table a script right run script now this is going to require a little bit of code right I'm going to add this piece of code in uh in the free resources in my free community too um if you if you want to know how to do this specifically with with air table here we have the the web hook URL right all you'd have to do is copy that that script and put in your web hook URL here and of course Define your specific trigger right so let's say I go back here to make.com I didn't I didn't create the web hook yet I guess I didn't click on save so just generate a new one so here we have it cop copy the address I go back to the air table I add it in there right now here we have to Define what we want to uh send send over to um to to the web hook inm make.com now we want to send over the record information right so we can just go air table record ID I made a small mistake here I need capital I because that's how I defined it here in the script and then then basically what I can do here in make.com is run once and basically you see the web hook now uh it's going to it's basically waiting for information to be received right so if we go back to aor table we can now click test right and if we go back to we can see that it ran right you can see it received data and the data it received is the record ID right which are defined right here now we can send over more information but I'm going to show you why I only sent the record ID because now we know the automation is immediately triggered as soon as I click that checkbox right and what I can do now is go to their table and say get a record right and here I can just simply add in that same base again uh here we go and you will see that it asked me here for the record ID which now I can use I got from that web hook and I can use in here and this is these are variables right which I haven't gone over yet and I think it makes intuitively a lot of sense but these variables just all these variables do is they store data right and of course these are variable because every time this web hook runs it will be a different row and a different ID Etc so all we Define here we can just click it here so as soon as we open this we see this pop up we can Define the record ID we can click on Save and that's it so for example we can try it again now right so we again can click run once to test it we click here on test if we go back here you can see it received it it passed over that uh specific ID to to get a record and you'll see in the output now we get that bundle of that specific row back right with all the information now one more thing I want to explain is web hook responses and you can see here if I click on web hooks now we get another option here which is web hook response and through a web hook response we can basically make sort of an API call out of this make.com scenario so we can actually send information back in this case to a table now this might not be the best example because we don't really need to send the information back but I for example use this a lot with relevance AI for example where I Tred to make an agent that can uh use a mate.com scenario and can actually send information back right so for example a common one I use I'll show you very quickly is uh for example relevance AI is a if you don't know relevance AI don't worry um but is an AI agent Builder right and and what relevant say I misses is for example Google Docs integration now make.com has a Google Docs integration so what I do is I just make an API call from relevance a I add in that web hook I send over the text that I want to add into a Google Docs I've added that information as you can see title and Report into the Google Docs module here in make.com so this creates a Google doc and then I use a web hook response to send that information back to relevance AI so my agent can actually use the the link of the doc right and that's what this web hook response serves for as you can see here you can Define which variable what data you want to send back right and as soon as you as soon as you add a web hook response basically what will happen is the the software will wait for a response to get back so you don't always need it if you don't need information back to the the software you won't need it but for example for this relevant sayi agent usually want the agent to receive information back then these web hook responses can be very useful now if this does make sense make sure to check out one of my relevant tutorials and I think you you get the idea very quick so let me get back to my presentation so we've covered these again if you want to look at all of this in detail I'll make sure to put the presentation uh in my free community so uh if you want to check it out make sure to uh check the description below I'll put a link uh to the free community so that brings us to filters and routers which you're in practice going to use quite a lot when you're building automation systems um now filters speak for themselves right basically are conditional checks to let bundles through or not right for example only process status is approved now routers split workflows into multiple paths each with their own logic or actions or workflows right use cases of course can be to sort incoming data filter data or create parallel workflows for different data types or records in this case so if I go back to my initial make.com automation um for example let's say we want to add in a filter we can say something like we only want to process videos with over 10,000 views let's say so what we can do is add a filter now I already know that we get the amount of views um from the RSS module right that's the data uh that the RSS module brings back right so uh for example you can see it here right in the output I think it's here in the RSS field sometimes you have to look for these uh specific values and it takes a little bit to find them but uh you can see I think it's here media statistics here we have the views right so what we do is basically we don't want to put the filter all the way at the end right because otherwise we're processing all of these um these these videos or all these modules uh will cost an operation if we're actually not going to update the table so we want to put it as close to the data point so in this case we can put it in here right and as you can see we have these little lines and then we have this little icon here and that's basically where we can add in filters right so in this case I'm going to put it here click on that and there you have setup filter now the label is just to name it so we can say uh TH or 10,000 views right and here we can set up the condition now here of course we have to add in the variable from the RSS module right with the view count so again we look that up which is going to be here media statistics now when you do this always important to to do this to select the right value here right because if we select properties it's not going to work we have to select this one views right and then here we can Define the condition right so you have lots of options here available now this in this case it's a number so we have to go with numeric operator so we go with greater than and then we add 10,000 right and now you can see the icon changed here to little filter funnel and now we have the filter applied so if we run the same automation again we can see this one now produced three results let's see if there's any filtered out right now so you can see now they were filtered these were filtered out right so only one was actually uh more than 10,000 views right so that's how filters work pretty straightforward I think now for routers um let's say in this example we wna have a video that maybe a video that has over 20,000 views we wna besides just updating our a table we want to notify us through slack just as an example so what we can do is separate this one for example we can click here on on link and then we're going to add in a router right because one workflow has to only update the air table the other workflow has to uh notify me to slack so what I do here is I can either select here the router or I can go here into the toolbars toolbar and then in the flow control settings you'll also find the router right these are common modules you're going to going to use right so here we add in the router right and then we can Define as many paths as we want really right now in this case we only need two can see it automatically connects um and in this case we also want to notify ours through slack say right so we just add in slack Slack's already connected with me so we can go with create a message uh here we select the channel right so let's just send it to General right and then maybe what we can send over is the YouTube url right so we again we just select that variable in this case from the air table right and then we click save right now for the other route we can just clone this right which is useful feature too right just cloning right and you can see it auto automatically attached and we can do different routes so let's say we want one for when it has 10 more than 10,000 views one for when it has less than 10,000 one when it has more than 20,000 I don't know if it's this is the best example but you get the idea and you're going to use routers quite a lot I'll show you an example of an automation we run with lots of routers in a second now you can see if we don't Define a filter now in this router it will pass it on to both right so in this case we're going to add a filter here which says let's say 20,000 views right we do the same thing we go back to the RSS module go to the view count we select greater than and in this case 20,000 we click save now we have the filter applied now there's one more option here which is the fallback route like let's say is a backup route that is used if the source data didn't go through any other route right so you can Define this you don't have to let's say it doesn't match any of the filters if we put another filter here then we can uh Define a fall back route if if it doesn't match any of those right so that's it uh now in this case let's say we can put in a completely different workflow here right now this case we keep it simple probably we could have done this only with a filter but you get the idea right now let's try this again and you can see it didn't have 10,000 views as you can see 20,000 views so it went this route right so that those are routers I can show you a quick example of uh one that we we have with many routers for example our inbound leads so you can see we have multiple routes here depending on the in the type of inbound lead we get in and we have another router inside of a router here Etc so you're going to use these quite a lot in practice let me get back now the next thing we have to understand is really how to set up custom apis which we do through http requests now why is this important when when would you actually use this now there in practice when you're working in make.com you'll basically find three uh use cases where you actually need to work with custom apis right the first one is when you want to add a software into your workflow or your automation that doesn't have a native integration with make.com yet now because make.com has so many Native Integrations and especially with all the popular softwares this for this use case you don't come across it very often right almost all of the softwares we use on a basis and you probably use in your automations will be available as a native integration in make.com but sometimes you'll find that uh a specific software is not yet integrated and then we have to work with custom apis through HTTP requests now again I have done hundreds of automations and I I can probably count on one hand the times that the software was absolutely not integrated with make.com yet now the Second Use case is when make.com actually has a native integration with the software but doesn't have the specific action that you want to take on that software so let's say uh a software in their API and documentation has lots of different uh types of actions we can take but make.com is only listed maybe 10 and it doesn't list the one that we actually want to do that's where we also have to start using and knowing how to set up custom apis like the the example I said before right let's say we have air table we do have a native integration um but let's say uh you can see it's pretty limited the amount of of of things we can do here let's say uh we want to Archive a record I don't even know if that's actually possible but just as an example then we can use this make an API call here and then you can see we still have to set it up uh ourselves right so we have to understand how custom apis work and then the third use case which you come across most often in my experience is for scraping now when you're building these automation flows and and and workflows Etc in practice you're going to use a lot of scraping right because a lot of times we're trying to get data from a specific Place transform that data to either generate content or uh maybe qualify leads Etc but usually we have to get data from a website or from a social media Etc so scraping is a very common use case and usually we need an HTTP request to get access to a scraper right which we do through an API call so very quickly if you're new to apis I'm going to explain it very quickly literally in a few minutes you'll understand how apis work and you'll know it for the rest of your life so don't be intim intimidated it's actually really easy so what API apis are application programming interfaces and they are what allow different softwares to share and uh data and work together right so so you can think of it like giving apps structured way to talk to each other right which they usually do through Json which you now know what it is right now there are four important points to understand uh in apis which is the first one is endpoints and endpoints are basically like specific addresses where the API is accessed and each endpoint usually represents a spe a specific action that you want to take inside of the software right and these are usually just URLs right for example right if we want to create a hopspot contact right in hopspot this would be the endpoint right and you can usually recognize the action we want to take here at the end where we have contact in this case for for hopspot now where do you find this you can always find these uh this specific information on the documentation pages of websites right so let's say my CRM is uh AO right so if I just type in AO uh documentation right you will you will find all of this information in there right so in this case I go to reference and here you can see all the actions we can take with the AO API right you see list objects create an object get an object update an object Etc right and here inside you can see we find the end point right so that's how we identify it so that those are end points then we have HTTP methods now HTTP methods are basically used to define what kind of actions we're taking so the most common ones are which you almost always come across which is first of all get and get is usually used to retrieve data uh in the hopspot example right pulling a contact details right getting contact details then we have post is to create or send something uh for example creating a new hopspot contact then we have put or patch which are a little bit less common but it's usually used or sometimes used to update existing data like editing a contact detail and then we have Del lead to remove data right so if we look at AO again we can find this in the documentation pages right so you can see for every action here we get the method get post get patch get post get patch right so very easy then we have headers and headers basically carry some important data about the request usually it's like instructions for the API on how to process the request the most common one headers you have to include in your HTTP request are authorization and this basically tells the API who you are and if you're actually authorized to make this call to the API right and you usually do that through an API key and the second one is the content type which is a very common header you'll almost always find this and this specifies the specific format the data is being sent um into the API call right it's almost always application Json because almost all a modern apis work with Json right so an example for hopspot is beer and then you you have to add in your API key so this is very common right for the authorization so this would be the header and this is these two are the headers and these are the values right Bearer then you add in your API key which again you can usually find in the documentation page and for the content type it's application Json so again if I go to AO uh we can go here to create an object for and in here usually you can find which headers you can see right in this case it's accept application Json right authorization and a content type so in this case we need three headers right but that's that's the thing you can usually find this information here on the side too right so we see the request is a post the URL is this and these are the headers we we'd have to include uh so that's it and then lastly it's the request body and the request body contains the actual data we're going to send uh to the API right to the software so for creating a contact in hopspot the body might look something like this right properties and as you can see as you now know this is just a Json with structured data right so we want to send over we want to create a contact with this email right this name and this last name now again we can usually find this request body uh in in the API do documentation pages right so if you go here on Json usually you can get an example and here you see the structure they expected in so in this case if we want to create an object in AO right we know we can also check here which ones are required so these are required these three and of course we can add in all the domains or specific columns we want to update to so that's all an API request is right so if I go back to the automation we you can see we have one custom API call right the HTTP request here right and this one of course extracts the video uh transcript right from the video so this one gets the new videos and the amount of views right now what this text paror does is basically uh from the video URL which we get in this one it extracts uh only the video ID right which is what we need to actually scrape uh the Youtube transcript right this text par I'm going to explain uh later in this video how text parses work but that's all you have to understand for now right you can see in the output we get the video ID now this HTTP request how did I set it up basically what I used is rapid API and Rapid API is basically uh an API marketplace with lots of pre-made uh apis that are ready made for us to use right and they have lots of social media scraping web scraping and all other kinds of of scraping apis available for us and make it really easy to scrape things I'm going to explain uh scraping in more detail in the next section so you can see API Marketplace so you can just sign up for free right and you can see in this marketplace right we have uh lots of different scrapers available right Instagram scraper uh Amazon data Twitter LinkedIn hrfs Etc now in this case we used uh the Youtube video summarizer this one and now that you understand how to set up apis this will be really easy because you can see here we get all the information we need to set up our API right so first we see that the request is get because of course we're trying to get information from the API now here we have the URL which is going to be our endpoint right so we can copy that so let's say I'm going to set this up from scratch all I do is uh set up here the HTTP request then you're almost always going to use a make a request option right and we're going to add in that URL now you can see in this URL we actually have the video ID here right now they already filled it out with a default one but of course we want to change this for the specific video that we want to scrape and that's going to change so we want to add in that variable and we got that variable from the text parser module right so we can find it here and we just add in that variable so we scrape the the Right video right so that's what we do here the method of course is get and here we can find the headers right so we have two headers as you can see the first header is going to be this and here you find an header headers option right and here we can just add headers so we have two headers the first one has this name and this this is the value right and the second one is this one which is the API key which is very common to add into the header right now in this case because we're using a get request we don't actually have to send data to the API so we don't even need a request body which I showed you before right because sometimes when we use these scrapers we don't actually have to send data so we don't need a request body also because we already added the variable of the specific video we want to scrape inside of the endpoint in inside of the URL here right so but if you would have to add a request body all you do here is Click raw in the content type again it's almost always going to be application Json and then here you can paste in the Json right the request body now you're always going to select par response because basically make.com structures the output data for you if you uh click this on yes so you can always click it on yes uh so that's it that's how we set it up and then we have a set up to SCP scraper quite simple I think especially if you understand custom apis so that's exactly what we did in this one as you can see exactly the same setup and then we get the YouTube transcript back from that API right that's it so that's it for for custom API so if I go back so let's go to the next section which is scraping right I briefly touched upon scraping right now but uh scraping is an extremely important and useful skill uh to know when you're building automation because many of the automations you're going to build will use some type of scraping right either it's web page scraping or social media scraping uh you can get data from external sources or web pages and you can of course do something with it that data right very common for uh for example lead qualification systems or outbound uh email systems or content systems we want to get data from another place do something with that data and output it somewhere else so very useful skill and I basically divided it into six types of scraping and I'm going to cover all of them how you do all of them but basically if you know these six types uh you can you can scrape 99% of the of the internet right so first I have simple page scraping and what do I mean with simple page scraping it's simple page scraping is just uh the majority of web scraping right if we want to scrape uh a size landing page if you want to scrape a personal blog any web page scraping uh is sort of simple page scraping then we have S map scraping which with sitemap scraping we basically get all the URLs from one domain which sometimes becomes useful when specific information is maybe not available on the homepage or but on another page we first have to find that other page before we can scrape it I'm going to give you an example later to but it's very useful to notice then we have web crawling right and web crawling what it does is it basically scrapes uh the all the URLs all the content of all the pages from all the URLs of the web web page right so and a common example for this at the moment for example is let's say I want to build an AI assistant or an AI agent that has is trained on all the data from the make.com uh doc documentation right so it has that specific knowledge so we can ask that assistant or that agent questions and it has the specific knowledge on the make.com documentation then we can use for example a web crawler to crawl and and scrape all the content from make.com documentation pages right so that's what a WebCrawler does and usually they take a bit longer of course because we're we're crawling lots of different pages and we have social media scraping of course very common and very useful to know right you can scrape LinkedIn for example to qualify leads or personalize emails we can scrape Instagram to come up with new content ideas or YouTube what I showed in the in the example but yes this is very useful to know and we have Google scraping which is also going to be a very common use case when you're building automations right scraping Google results uh for example we only have someone's name and we want to find their LinkedIn to be able to scrape their LinkedIn we can first use Google a Google scraper to uh scrape someone's LinkedIn then we pass it into a social media scraper to actually scrape their LinkedIn right and then lastly I have what I call complex page scraping there are some types of websites that put anti scraping methods in place right so they basically have some uh defenses to make scraping a little bit harder to do right and therefore I separated it because usually we have to use different scraping methods to bypass those right and these three we these methods we can't use so for example e-commerce is a very common use case where they have heavy protection in place like Amazon or or any any e-commerce usually has pretty heavy protection then we also have some websites which are maybe login protected or have cookie popups or captas things like this so uh for those types of websites uh we can use different types of scrapers which I'm als also going to show you in a second so let me start with simple page scraping where we can basically with these three methods we can already scrape 90% of the internet right so the most straightforward and simple way to scrape a page is through an HTTP get request now I'm going to show you this if I'm uh go back to make.com and let's say we're going to uh do a new new scenario so let's say I want to just scrap my uh personal website right and make a summary so all I do here is add an HT P make a request right just as we did before with the API call and we literally don't have to do anything here we can just paste in the URL of the website we want to scrape right so let's say my website right we just add in this URL and what this HTTP request is going to do is going to make a request uh to the website and retrieve back the HTML right so I can click here and po response which you always do right save and if I run this now you can see here in the data the out put we get back the scraped website the scraped HTML as you can see there a lot of HTML tags I took a very long format right because we got aot lot of these HTML tags which of course is a bit me messy but now that we have ai scraping has become so much easier right because traditionally when we were scraping and we wanted to extract a specific data point right it's pretty hard to program in uh exactly which part part of the HTML to to extract Etc now but now with AI we can just pass this in ask the AI what to extract and the AI will do the rest right so it has become a lot more uh accessible to to non-developers to to be able to scrape right so let's say we want to make a summary on my website so all we would do first is we're actually going to clean it up a bit because again we get all these messy HTML tags which we don't need we only want the text right so again make.com has some built-in modules so we can go to the text parser and I'm going to explain the text parser also in more detail the other options uh later in this video but we have one option here in the text barer which is again a build team module.com which is called HTML to text right and you can see converts HTML to formatted text it's very useful for these scrapers all we do is add in the variable with the data with the HTML right and we can't finish a scenario with a text parser so we're going to add in an open AI module right away to make summary again I'll go more in more depth over the AI Integrations also later in this video but I'll show you a quick example so let's say we're going to use GPT 40 and we want to make a summary of the website for example we want to use that for sales rep to have more information on a new incoming lead right so we can just add in a prompt here we can go please summarize what this comp do based on the scraped website here below and of course we're going to add in that uh cleaned up right uh scraped website click save now we can run the scenario you can see now that here in this text it already cleaned it up a bit as you can see right it's still a little bit messy but it's a lot cleaner as you can see we don't have those messy HTML tags anymore so we pass on a little bit cleaner data onto the uh openai module right which of course saves us some cost too right now you can see here we get the results this company specialized in helping businesses Implement AI driven automation to scale their operations without hiring additional staff their services include AI strategy and road map design AI powered marketing and sales Automation and real world's AI implementation high volume operations so pretty good so that's it that's the e eest way of scraping right it's simple get request you can see how simple it is actually to do this right with AI now now the thing with the get request is it is the most straightforward and cheapest way to scrape but it's also um the one that's going to work less right as soon as a web page has some anti scraping method in place or even has JavaScript rendering which some websites have right which basically means that the code first has to load before the HTML shows up and in that case there's a delay uh between when the HTML shows up and then it will fail right because this will request HTML right away but it's not yet loaded so this won't work for all websites right so if this don't doesn't work for a website what you can try is another uh scraper right so the two other options you have for simple page scraping is again these marketplaces right appify and Rapid API so again here in appify we can use this simple web scraper it's good when you choose a scraper here to look at the amount of people using it and the and the ratings then you know that this this is probably a good scraper right so this is a simple web scraper you could use or in Rapid API we also have web scrapers available now the third option which is fire crawl now fire crawl is a very popular scraper too at the moment and for good reason they're they're pretty good so this is fire craw right uh they're pretty cheap too so you can see we actually have 500 scrape uh credits I think it's one credit per per uh page scraped and it's $ right and then we have for $3,000 we have $16 a month right and it's a it's a pretty good scraper so let me show you an example fir craw then I'll show you an example of epifi and Rapid API later so let's say uh you you've signed up here right here in the docs you can see the types of scraping we have available here we have actually crawling and mapping also available for now we're only going to scrape a page you can see we can actually use bat scrape too so we can scrape multiple websites at the same time time in this case we just want to scrape one now again we know how to do this right so we got all the information here so if I go back to make.com let's say we're going to add in a new scenario again we just use HTTP make request now just paste all of this in so I don't have to go back and forth but we can see we uh the method is going to be Post in this case so it's always good to check it the headers are here content type application Json right in the second header here now this is common right where you have to add in beer and then your API key so if we go back to fir craw I should have an account yes it log me in so here you can find the API key we copy that and we add that here uh with a space after Bearer right then uh the request body we can find here as you can see right this is the Json right now of course we're going to delete this because we only want the end point here and now we actually need a request body right so we're going to click choose raw application Json and here we can add in the request body now you can see we have the URL which we can Define and the format so in which format do we want to retrieve uh the results now in this case we don't necessarily need HTML right because markdown is a cleaner way of getting it back right so I can just delete this right and in the URL let's say you have a a lead form or something then of course you can add in the variable here too now in this case I'm just gonna put in my website again wrong one yeah so if we run this we get it back right so here we get the data and you can see it's a lot cleaner than that get request that we earlier did right because we already got the mark down back so it's already sort of a cleaned up HTML basically so that's another way to scrape which you can try if it doesn't work on a specific website with a get request and you can also try always those those scrapers on rapid API or or appify now let's go to the second scraping method which is sitemap scraping right let's say we have a lead form and we get the company homepage basically in there but actually we're not that interested in it we want to know uh what the team page is for example right so we can extract more information from their team who they are what their roles are Etc so then we can use a sitemap scraper now again fire craw again you can do this again you will have some Sid map scrapers available in amplifi Rapid API but fire craw also has one as we could see before so here we have a sid map scraper right and it's a very similar way we can even as you can add in a search and response will be an ordered list from the most relevant to the last least relevant so let's say we want the team page we can go with team right or about us so let me show you a quick example so let's say I'm going to add one more here make a request now in this case the UR is going to be this one you can see changes here right to map I'm pretty sure the headers are going to be the same usually they are so I can just copy them from here because the headers are usually defined by the type of application then we have of course authorization which we already put in the other one and the body type J application Json now we have to add in the request content which again we can find here so let's say we're going to add this search to it's just going to sort right it's still retrieving all all the the URLs from a specific domain but it's just going to sort it for a specific one so let's say I don't have a team page so let's say blog I want to find the blog a website we go par response and we're going to add in again my website just as an example so if we run this one now so I made a mistake it's because of get it's actually post so now it should work and now we get a back and now you can see we don't get we don't get the the content or the HTML back we get all the URLs of my website right and now of course let's say we're looking for a specific page we can add in an AI module right that finds that specific page so for example I could say something like so I could say let's say I want to find uh the blog or all the blog Pages for my website right because I could want to scrape them after this right so for example I could say look at the S map below IP put all the blog Pages um output all the blockes only output the URLs right we add in in this case we use the second one the links add it here at the bottom we click on Save and if we run this again now you can see this one I puted all the links and now the openi module is extracting all the blog links which for example we can then pass on to a page scraper to actually get all the content from there right so if we click on results you can see it extracted all the all my blog see post right it identified the blog articles right so this can be very useful right if you're looking for specific information that might not always be available on the homepage right that's where we can use S map scrapers now for the third one uh is crawlers now I gave you the example already uh of let's say the make.com documentation so we can take that as an example now again we have fire crawl also has a crawling option as you can see here and again you can also do this with API file right for example but I'm going going to show you in a second how to set up a scraper with apii um so you know how to do it with any scraper you want right but here you can see we also ah actually here we have a website content crawler right but we're going to use fire crawl again right so if we go to crawl here you can see we get this is the information we need you can see we can add in a limit so the amount of pages you actually want to SC crawl to not overdo it because can imagine some websites have literally thousands of links so if we're going to crawl every single page it's going to be a lot of content and then we can also have the scrape options again here right the format now let's try this one so let's try with the make.com documentation page I'm just going to add it here uh make request again so we're adding in the request body again application Json we add it par response now we still miss the barer the API key so I can just copy this right and then we have to Define of course here uh what we want to scrape so let's say we want to make uh make.com developer documentation now this going to probably be quite a lot of pages here so we want to get the the the URL here which includes all the documentation pages so let's say okay okay here API documentation so this should be the base URL because it basically it's going to scrape every URL that has something attached here so if I click here yeah you can see that it adds it here so I'll take the base URL all right I add it in here let's say we do just for now a limit of 10 and we want to get both formats back so we click save is there something missing yes this of course we have to delete so that was faster than expected let's see what happened okay so it's seems like okay I get it so if we go back to the documentation yes so because this crawling can take of course really long if we're scraping hundreds of pages the way this works is we actually have to if you're using curl or I think this will return an ID where you can check where you can you what you can use to check the status of the crawl right so used to check the status of crawl job and gets it results right so we'd have to use another API key here to actually check when it's ready and to actually get the results back right so let me show you quickly and that's a good opportunity to show you for example a weight module so let's say this actually takes you know 3 minutes and we can add in a sleep module here which we get into tools and we can wait before we check for the results right so let's say we want to check for the results right we set up another one in this case it's get right because we're going to get this want to get the status and you can see here in the URL we need to add in the the crawl ID right which of course we get here as you can see right so that's it and then uh the headers are the same we click save now let's see I'm going to put in the delay little shorter but if we run this module now only we can check we're just pasting the ID manually right now here we got the ID just so you can see how this works right this basically if we want to test it but we need a variable then we have to fill it out manually right you can see if we get it back right now yes you can see now we get all the data back from the document you can see it's a lot of data now let's say we want to make that assistant or that agent we can then add this into a database or a vector database like for example an open AI right and then uh we can give that Vector database to an AI agent or an AI assistant so it has that specific context and information on the makeon documentation page so you can do that in here too for example add files to Vector store right I'm not going to show that I'm going to show the the whole AI integration in more detail uh later in in a later section so that's it for crawling now we're almost there with scraping the next one is then we have social media scraping and Google scraping now both you're going to use uh quite a lot when you're building automations right I mentioned some examples before but uh yeah knowing how to do this is is going to be very useful uh now social media websites are very uh Ed against scraping right they usually make it really hard for us to scrape so these traditional scraping methods are are not going to work for social media websites but luckily we have appify and Rapid API where people build API specifically to scrape all of the social medias right so if we go for example to the appify I already showed rapid API right we have all the social media scrapers here right Instagram Facebook Tik Tok uh not Tik Tok you have multiple scrapers usually per platform where have Twitter YouTube Etc so and for Google uh the easiest way to scrape and by the way Google scraping is also very common right uh sometimes you need to extract uh URLs from a Google search for example uh and and in practice you'll use uh the Google scraper quite a lot in many automations right so the best way to do that is through the serer API so I can show you quickly Ser API as you can see here the world's fastest and cheapest Google search API right and we get 2 and a half thousand free qu Ares so you can just sign up for a free account I already have an account right so uh let's say I want to build an automation uh which includes both both of these just to show you very quickly um let's say I want to I have uh hypothetical scenario I have a lead form where inbound lead fill out their data and let's say I only have access to or they only fill out the name right but we want to actually do more research on that incoming lead to get some more data points maybe know where they work what their job title is how big their company is and then output all of that extra data into the CRM we can even qual pre-qualify them uh so we get get some more information in our CR so let's say we want something like this uh I can show you very quickly how to build that in make.com so let's say we could have the trigger with a lead form now I want to focus this on scraping so I'll just uh pretend like we have a lead form as the first one but I'll I'll go for the scraping right away so again for for the Google search we're going to use an HTTP make a request onjo again right and we go to the serer API again this is free right here we get the URL we can see that the method is post we have two headers and then for the body type again as always we do raw application Json and the request content we can find here now as you can see here in the request content this Q basically means query so what is the Google search query we want to do receive results for right now in this case we're trying to find the link URL of a lead right so we just pretend like we're adding the variable from the lead form right now which is the name right so in this case let's do mine so this would be the variable right and then we can just add in LinkedIn right because most likely with that Google search query will get back the LinkedIn Euro right again we do p response and if we run this now as you can see here in the data then we click on organic here each one of these is basically a Google search results so we get the first 10 results back right so you can see actually in this first one it already found it so we can add in a open AI module of course that can extract the the right URL right so for example I could say uh please extract the LinkedIn URL of and then I could pass in the variable of the name again right so let's pretend this is a variable um B sple only output the URL nothing else right then we add in the data of course now we can pass in uh the array here right really important so because you can see we have multiple data points we just pass it if we click here on organic it won't actually receive the data right so we have to click in these separate so we have the title the link and the snippet that should probably be enough and automatically we'll pass that in from each of the search results right because we get it into to an array so can you can see that here too right because you see the square brackets you know it's the array of values of this specific uh uh data so we click save so we can try this again and now we can see the result is my LinkedIn profile so perfect and now we can of course use a LinkedIn scraper to actually get some more data points right so uh let me show you for example how we do that through apii right so in apii again right we have all these these uh scrapers right now let's find the LinkedIn one let's say LinkedIn profile scraper right you can see this one actually it's $25 a month but we have a three-day trial you can do try for free now I actually have set this one up already um you can see here your your actors right the ones that you use uh now I have already set this one up so the way here on the left actually for this LinkedIn scraper we need to add in cookies right for in order for it to work right so the way we do it here are follow these steps right install cookie editor so you can just install quick uh Chrome plugin I already have it right then you'll have this appear in your uh plugins then you go to your LinkedIn profile or your LinkedIn wherever in LinkedIn right you just click on that cookie button you click on export Json right and you add that in here right so I can do it again just so that's it now you can adjust some other settings here if you want to right but all this is is little bit of a front end basically because if you can go if you go here on Json uh you'll see the actual settings are here so it'll just update the actual Json right so we can copy this too and as soon as you've use this copy this not should have a copy button maybe they have but I haven't found it so that's it then you go back to uh make.com right and let's see make.com which one this one right and then we actually have a native integration here with appify as you can see right the way you connect this mine is already connected uh but in this case we're going to go for run and actor right and the way you connect it is through your API key Now API key where can you find it if you go back to appify you can just go here to settings API and Integrations here you have your API key so you can copy that in then you have your connection set up right and then if you've used one already you'll see it appear here right or if you've added one uh in appy so in this case we go for the LinkedIn profile scraper now we're going to toggle run syn synchron on right um basically it will make sure that it's finished the scraping before it ends now if you're doing a re large uh scraping job that takes a really long time then maybe you want to do no and uh start another scenario where you actually get the results but in this case we're just doing this one and we have input Json which is the Json I just uh copied right we paste that in and you can see here we have the URLs right and here of course we would add in uh the variable of open AI which is LinkedIn URL right this we don't have to have to change then we click on Save now if we run this can run it what you'll see here is we don't actually get the scraped uh data back yet right we just get status succeeded so we've just triggered the the scraper basically but we need to add in another module here of appify which is get data set items where we actually retrieve the results right so we select that one and for the data set ID we can find that in the output of the previous module we go here to if I remember correctly here we go default data set ID right so we select this variable data transformation we can select clean format Jon now in this case we only want the last result so we uh just limit it to one and that's it and then of course we can add in that open AI module at the end right just let's just run it and now we should actually get the scraped uh data back from the LinkedIn Ur and you can see right occupation right picture cover image positions right education so we get all the information from the LinkedIn profile and now of course we can pass that into an opening eye module we can say something like make a summary uh on the lead uh based on again we can add in the variable now you can see we have lots of data points so we can we can uh we have to sort of add them in manually here so we can for example go right positions right and we automatically retrieve all the five positions we can go first name already have that occupation Education certification so we can add this all in whatever is relevant to you industry right location country job title company company LinkedIn URL which again we could use to scrape the company LinkedIn URL too right let's just try this for now just an just as an example and then we run it again and we get the summary right it professional founder Beni uh specializing helping businesses become AI first companies bachelor's degree blah blah blah blah right and then of course we can output this into a CRM but you get the idea now let me show you the last uh way of scraping which is complex page scraping which I said before some websites have some Protections in place so we can't use these uh more simpler ways of scraping so we have to use more advanced uh web scraping apis now the best two I've found our ninj scraper which is available in Rapid API and apii I think so uh but for sure on rapid API and uh by far the best one uh we've found is Scrapper fly right so I can show you and again right the most common ones you see here are e-commerce websites usually have pretty heavy protection in place uh we work with a lot of e-commerce too so for example companies that want to scrape competitors prices Etc uh then uh we use use the Scrapper fly usually because as you can see uh they have some some extra uh me me in place to bypass these uh the these protections right so we have automatic antibot bypass proxy rotation basically changing your IP so uh you don't request too many uh API requests from one IP which usually get blocked uh JavaScript rendering and uh real web they mimic real web browsers right so if I go into the dashboard again these these these things are pretty cheap in general right uh you can see I'm here on the plan where where the plans I guess the plans we can find here yeah so depends on how many how many request you want but you can see 40,000 API credits is $30 a month if you're here in the dashboard you can basically play around uh with with the settings too right so you can see we have all these extra settings here we can play around with right so we can put the geolocation we have an antibot here uh right so we can select anti- scraping protection on on right we have browser JavaScript rendering here we can put in a delay which sometimes helps right we can Define that too and here we basically can can put it in just like an ampify whatever you want to do but usually the default Works already and then it will'll update update it here so we could go for example to the curl if we want to use this in in uh make.com we can copy this now this one is a little bit different um we have to add this information I'll show you quickly to make a request so we have this information of course the URL again goes here right then we all get these data URL encode these these values here and these values we're going to add in this case into the query string not in the headers in the query string so these are the names right and these are the values right now I'll leave leave it for that like you do that for each one I've done enough by now but if you can't scrape it with any of the traditional methods try it with scrap scrap a fly because usually it works so that's it for for scraping now literally knowing this you can basically scrape 99% of the internet so I think this is very useful uh when you're building automations because most of automations you are going to include scraping now let me go to the next section then we have uh iterators and aggregators now this can be a bit confused especially when you're starting uh and I think make.com is a bit to blame because these icons and the names are not extremely clear I would say but uh it's not rocket science once you once you understand it so uh why do we use these first of all uh we can use these to basically process iterators we can use to process multiple items inside of a list or an array right uh separately right so if I have my example uh from the the competitor tracker right we have a list of uh YouTube URLs and we want to process the automation for each of the URLs separately right so for that we would use an iterator and an aggregator does the opposite right it takes multiple items and combines them into one now to really understand how they work in make.com it's really important to understand bundles right and what bundles are in make.com specifically because uh the way it works in make.com is a bundle is usually just a Json or an object with stored value right but in make.com specifically bundles are the ones that are separate separately processed so as soon as you see a a module outputting multiple bundles you know that the next module is going to run the automation for each of the bundles separately right so it's really important to understand uh bundles and basically what the iterators do is right they take one bundle with an array right and output it into multiple bundles right that's all an an iterative does so it takes one bundle let's say with a list of values and then we output it into multiple bundles so that the next module is actually going to process each of the values separately so if we go back uh to uh the automation right let's run this again so what you'll see here in the air table uh module is we actually get 12 or 11 bundles back right and each of the bundles stores the value of the row right or the record in air table right and you can see because we have 11 bundles here the second module the RSS module right which checks for the new video runs 11 times as you can see because it runs 11 times on each of the rows or records or bundles in make.com now knowing that you might see that actually this module air table already has a built-in iterator in here so we didn't even need to use the iterator module like here um now that's basically because make.com already identifies that we most likely want to process these records or rows uh separately right so they basically added it in this iterator module inside of this this module and you'll see that happen a lot with uh the databases connections you have in make.com with Google Sheets click up crms they'll automatically output it into to bundles but if you look at it in reality the raw data it's just an array with objects right so uh that's it but make.com makes it a lot easier now sometimes of course uh if it's not a built-in connection Etc we do have to work with iterators like I'm going to explain this in a second but that's how how it works now if you're still confused let me uh just show you a quick new example just going to show you a random example let's say we we're just going to build uh a new automation I'm just going to use some very random uh uh tools but it's just to give you an idea of how these iterators work so let's say we have a tool which is called the set variable which basically just allows us to make a variable right so we can just say um example right in the variable value uh we're going to create an array which we want to Loop over right so I'm just going to use a text function don't worry about not understanding this I'll go over text functions later I just want to explain how iterators work and show you how they work right so uh we're just going to make an array here and let's say we have three names right and we're going to separate the array by comma right right so what you'll see is this tool will run once of course right because and we only have one bundle and uh we in the output we get an array because that's what I did with the function right so we get three values with three names now let's say we want to process each name separately right so we're going to do an automation with these names or whatever and we want to run it on each of the ones separately and we don't have that built-in functionality like with air table then we would add in an iterator right and we add in that array right and we run it and you can see now we get uh three bundles back right so I can show it even clearer if we do another set variable example two and I put in uh this example with the name right what you'll see now is that this one ran three times so after the iterator module we've separated the array into multiple bundles now this next module ran three times right so that's that's how it works now for aggregators it's the opposite right so let's say and it's it's important to understand that aggregators uh they take multiple bundles so if I go back to the presentation really important to understand right they combine multiple bundles into one bundle right so it can only take multiple bundles and output it into one bundle that's why I think the name is a little bit confusing because it can't just take any array inside of one bundle it can can only take multiple bundles which of course is an array but you can only take multiple bundles and make one bundle so let's say for that air table one now this is a bad example of course because but whatever it's just as an example uh we want to take these 11 bundles and I put it only in one right so we can use an array aggregator right and here we can then choose which values from all of the separate bundles we want to combine to one bundle so let's say we want the channel let's say the video views right we can run it and what you'll see now is instead of these 11 bundles in the output we only get one bundle with an array with all the values right now let's say uh we want to combine all of this into a text because now we're getting an array back right from the array aggregator we actually want to send a text to for example send a notification and we have one more option which is text aggregator right so let's say we want to combine it into text and not into an array we can go to tools right and here we have three options which are called aggregators now these two you're not going to use a lot but you can also do numeric aggregators and table aggregators this case we're doing text and then we can just Define let's say uh we want to we want to combine the subscriber count right so so now you can see we get all of the subscriber Counts from all all of the ones back into one bundle and then of course we could send a notification with all that information now bad example but it's just to give you an idea so now let me show you how this this one works this iterator why it is there so I think there's a mistake here yes so the reason why is because this transcript I'm going to show you this better in a better way I'm just going to run this again the reason why is because this uh uh scraper here the way it outputs the transcript is in a really confusing way as you can see here data we get transcripts and then we get a huge array and basically it separates each of the sentences as you can see into a different object here right so we have a huge array with literally thousands of sentences now if we try to pass this through this data this array to open AI to summarize the transcript is not going to be able to recognize this this this data structure so what we have to do is we have to aggregate it right we have to put it all into one now the problem is this is only one bundle right remember array aggregators or text aggregators can take uh one bundle array and put it into one they can only put multiple bundles into one so that's why we first have to iterate over each of these sentences with an iterator so we get multiple bundles with the text of each sentence and then we can combine it all into one right so that's exactly what we're doing here right we pass in that array right so just just to show you you pass in this entire array and it's important to select the entire array not the value because then we're only selecting one and what you can see here is in the output inste we get one bundle as an input with the array and the output puts it out in in hundred thousand of bundles right and then of course we can use the text aggregator to combine and you can see you get the different values here already and we can just select the text and we can combine all of these bundles into one text right and as you can see here in output that's what happens right here we get the entire transcript and then of course we can pass it into jgpt I hope that verifies it a bit you'll probably have to play around with it a bit for you to really understand it but after a while I think these trades and aggregat they they start to make sense then we have uh some other built-in tools right in make.com I've covered a few already I think we've covered most of them uh but let me let me show you quickly so here we can go in tools right and we have get multiple variables get variable just gets the value of a previously stored variable you don't use this a lot can in increment function don't really use this this these you sometimes use set multiple Vari variables or set variables we can basically create a new variable for example we can change the name uh but in practice we use this more for example new variable to create to uh add a function right now functions are another thing in make.com where we can basically transform data in a fast and and efficient way now I'm going to go over functions at the end uh of this video at the advanced uh skills but I'll just show you a quick example why would why You' need a a set variable so let's say uh we have a variable and uh we use a trim function here and a trim function for example removes space characters at the start or end of text which is you sometimes have to use for example when you uh going to use an API call that after and API request bodies usually uh can give errors if there are too many spaces especially at the beginning of the end or the end so then we can use for example a stream function if I for example just put in a random value here with some spaces with uh space in front and after uh and we click save and we run this module you'll see that it comes out without a space right and of course we have access to a new variable in the next module right so if we let's say Slack create a me message you'll see now we have a new variable so that's the set variable then of course we have the Sleep which also covered mostly used for example for these API calls when you actually have to wait it takes a little bit of time uh before you can get it back or you have to do another API call to actually retrieve back the results and these sleep modules are common right you can just type in sleep and then you have a delay of Maximum 300 if you need more 300 seconds if you need more you can just string along a few of these sleep tools right also commonly for example we use it also we do an inbound lead email uh now we don't want to send that immediately so it doesn't look like an automated email so we actually wait uh a little bit with a sleep module uh and then we really have covered uh most of the important or all of the important uh buil-in modules in make.com the only thing we're missing here is the directives right and those are the error handlers and error handlers are important uh to understand especially if you're going to run uh important workflows or if you're going to give uh workflows or build workflows for clients now why are error handlers important because uh first of all apis fail uh sometimes they are run usually on external Services uh we don't have them under control and they do run into issues right so it's important first of all to have error handlers on apis and second of all the important thing we want to do is add in notification so if something goes wrong uh we do want to be notified so we can adjust the workflow and and update it and thirdly I would want to say most uh ation are going to run into issues well you can test it all you want if you actually run it into production and uh it runs on a daily basis on high volume tasks things will go wrong right so really important to add in error handlers especially on critical workflows important business workflows where data cannot be lost and if you're going to deliver this to clients right so those are the two important things right adding error handlers and notifications now make.com already allows us a really easy way to add in notifications right you can just here go to your profile right and let's say save uh and here you have email preferences now in general you want to turn these two on right for errors and warnings you get notified now don't do this when you're testing and you're building in your client's account for example because they'll get scared and while testing of course you're running into lots of issues so if I go back I'll show you the error handling so in practice uh you're really only going to use maybe two of these um I personally use only two of these these others I don't really have found a good reason to use them uh the most commonly used is the break module and the break module basically what it does it just uh if there's an error let's say in an API call right it will just uh try again wait first wait uh 15 minutes and then try again right so and here we can Define how how often and then try again because apis for some reason they sometimes just fail and nobody knows why but they really do so it is important basically for any important workflow or workflow you're going to deliver to a client add in one of these brake modules at each of the API steps so in this case I would add it here in open AI air table and air table so all the apis are covered and it really does resolve most of the issues uh with just a simple break module right so I literally added it on on all three so if we test this it won't work actually because you have to change the settings for aor handlers to be able to work right so in settings we have to uh change this setting here allow storing sorry of incomplete executions and this is why it's also really important these error handlers because if something goes wrong we're basically storing the data inside of these incomplete ex ex executions so it doesn't get lost right really important in important workflows where data can't get lost right this is this is really good and then we can actually go in after and resolve the issue so we actually don't lose any important workflow or data right so let's say we just add in an error here I'm going to add in the method put right which is obviously it's not so then you can see it run into runs into an error now of course we get notified first of all and second of all now we can go here in incomplete executions and you'll see now the error right and now we can actually go back into this specific workflow resolve the error have to save it resolve the error run it again and now the data is actually being processed right so we don't lose any data like this that's why error handling is important so uh what other error handlers do we have the only one you might use is maybe uh the ignore module and basically what an ignore module ignore error Handler does is if there's an error it just completely ignores it right uh now now the only reason why I've used this is because some apis were have returned me errors while they actually were processed correctly so uh if that happened if you see that happen it's really annoying because if a a workflow runs into an error I think three times it automatically deactivates while it was actually processed correctly so if if I notice that then I might add an ignore module because then it basically ignores the error and doesn't deactivate the workflow so that that's the only use case I found for this ignore so that's it for error handlers I think quite straightforward but important to know and I know many people don't actually use it uh so important to just add it on all the API calls it will resolve a lot of lot of headaches in the future especially if you're working with clients so that's really it for all the important modules and skills I will cover some more advanced ones at the end but now I'm going to dive into AI which is really going to put our automations now let's get to the interesting part AI integration now of course now that we have ai these automation uh Solutions we can build can really become 10 times as powerful as they tradition Al were right because besides just passing data from one API or software to the other now we can actually do something with that data in the middle right and that really allows us to automate much more complex systems and even entire workflows of of of humans right and it can also entirely transform business models right I'm going to get practical by the end of this section where I'm going to build something from scratch I'm going to build a lead generation system and maybe we can add a personalized Outreach system on top of that which I think will really help you understand how to build out your first automations and also to see this in practice but before I want to get practical I do want to go over the foundations so first I'll show you make.com AI tools they have some simple built-in AI tools and then I'll go over some of the fundamentals that I think are really important to understand uh before you start building automation Solutions with AI uh many people skip over this but I think it's really important to understand uh the types of L&M uh the L&M use cases understanding prompting Frameworks right and also for different types of lmms now these are really important because most people are used to prompting inside of chat GPT and in chat GPT we don't really need prompting Frameworks or best practices Etc because we can just go back and forth and if something goes wrong we just correct the model to get the final outcome but in these automation Solutions or systems we of course run this on hundreds or thousands of tasks and this has this system has to work reliably right so we have to really work and guide these N&M very well to make sure it performs reliably on large volume t tasks right and that's why prompting Frameworks and incorporating best practices is really important right then I'll go over choosing N&M uh prompt chaining and AI agents and then again as I said I'll build something from scratch which puts this Theory I think a bit more in practice so let me go first to the make.com AI tools so again this is a new feature of of make make.com maybe it's not new uh if you're watching this video a few months after I've released it but right now it's new it's actually in the beta version so you either might not have access to to it yet uh or it's an updated feature but basically what make.com has done and I can show you very quickly is they've built in they have now have a built-in AI tools uh module and basically what what they've done is take the most common or common uh use cases for AI and build it directly into make.com so you can see we have analyze sentiment request anything categorize text identify language standardized text summarizeed text translate text right so basically how this works is if if I click this for example translate text we don't actually need to connect open AI or or Google jamini or Cloud we can just do this inside of make.com and we don't even have to prompt the model right the module's already pre- prompted so it makes it a lot easier for us for these simpler use cases so for example if I go and type something in Dutch and we want to translate it to English if I run this now you'll see I get the translation right so that's it uh as you can see we have some other options we can say for example categorize a text also a common use case right let's say R an email hi um I'm interested in your services right and in here we can Define the categories right let's say uh leads promotions and spam right make.com we already have this sort of pre- prompted making it a lot easier for us for these simpler use cases so yes right and we get the category uh here let's see leads so did that that correctly and then it gives a reason to it so that's the AI tools uh you can see I have a few more and I think very soon they will add AI agents here unfortunately we don't have ai agency make.com yet but very soon they're going to release them and as soon as I do I will record another video on that so that's it for the make.com AI tools so then I want to go over very quickly the types of L&M you might already know uh but it's still important to understand we have basically have two types of L&M at the moment right we have the non- reasoning L&M uh and the non- reasoning lnms are generally faster uh cheaper to run and better for simpler tasks and examples we all know I think are the GPT 40 claw 3.5 Gemini flash each of the language model providers will have non- reasoning L&M and now we also have reasoning L&M right and reasoning L&M are generally slower more expensive but a lot better for more complex tasks right and examples are gp3 gp1 deep seek uh Gemini 2.0 thinking Etc and the best analogy I've heard for these um for these two types of models are these are basically system one level thinkers and these are system two level thinkers and what's the difference uh we as humans use system one level thinking for very easy and simple and intuitive uh tasks uh for example if we play a a game of tic tac toe we don't really have to reason and think hard for our next move right it's pretty straightforward so we can make an intuitive fast decision and then we have system two level thinking where we require a lot more planning and reasoning to uh take an action for for example uh playing chess right and I like this analogy because I think we can think of these types of L&M very much like this right reasoning L&M are a lot better when we have a complex task that requires planning and reasoning and these models are better for simple straightforward tasks so that's it for the types of nms then we have the L&M use cases now basically I've identified so of the main types of use cases we will find inside of these automation systems right now these are very broad categories of course there are a lot of subcategory underneath each of these use cas cases but I do want to lay it out to give you sort of a framework on understanding when you should use which type of L&M and also to what when you should use which type of prompting framework which I'll go over in a second so I basically have six here right the first one is extracting data now it's a very common use case right in these uh AI systems and L&M are generally really good like for example we want to extract a specific data point from a scraped LinkedIn profile right that's a very common use case we use in these automation Solutions or even summarizing it now again N&M are generally very good when they have a large context uh to extract specific data from it or even summarize that data right then we have generation again very broad topic but what I mean with generation is when an L&M has to generate a piece of content without a lot of context right and needs a lot more creativity right so for example writing a report writing a personalized email Etc then we have classification and categorization again common use case right categorizing emails then we have EV evaluation again can overlap a bit with classification or categorization but evaluation for example we can think of sentiment analysis or even evaluating if outputs from other other L&M models are actually uh good or not right that's also common use case uh then we have data transformation for example we need to structure a specific piece of text in a specific format we need a HTML uh format we need code generation we need Json uh things like this very common use case too and then we have decision making and decision- making is most commonly used uh inside of AI agents right AI agents have to usually plan and reason and think of which tools to use to um execute a workflow right or to get to an outcome that requires decision making so these are main use cases again take this with a gr of Sal there a lot of subcategories but I just put them here to give you sort of a general guideline on choosing L&M and choosing prompting framework so let me get to the prompting Frameworks now again you might think why do I even need prompting Frameworks I use jgpt or Cloud on a daily basis and it works perfectly fine again it's because that what we're doing inside of those apps is conversational prompting right and conversational prompting is very different than the prompting we use inside of these automation systems because we don't have the flexibility of going back and forth until we get the right outcome we always need the right outcome on a consistent basis and even when it runs on hundreds or thousands of tasks it always have to has to perform reliably right and therefore it's really important to incorporate uh proven best practices of prompting N&M to make sure we get it as reliable as possible and the best way I find to do that is through prompting Frameworks now just as a disclaimer this is not the only prompting framework or the best prompting framework this is just a prompt framework that uh we use internally in our agency and it helps us structure our prompt make sure we incorporate proven best practices but also aligns the way we write prompts uh across our entire agency so it's easy for us to to adapt and the third big reason I think is it gives you a structure in your head for how to write prompts in a consistent basis that that most likely will perform reliably at scale right that's the important thing so for prompting non- reasing N&M we basically use two uh prompting Frameworks we have the short structured uh prompting framework and a long structured prompting framework this is just how we call it right but uh short structured prompting Frameworks we use for simpler tasks and long structured uh prompting framework we use for more complex tasks and then for reasoning models we have a different uh prompting framework because we actually have to prompt reasoning models very different than non- reasoning N&M right non- reasoning anms in general need a lot more guidance and guardrails to perform reliably therefore we need to give it lots more context so for the short structured prompt again for simpler tasks we basically divide it into four sections we have the role and objective we have the instructions or rules we have examples and we have variables now for the role and objective we basically just give it a role and a direct description of the task now why do we do this because it's studied and proven that it most likely improves performance of these models right so we're just giving it uh a specific role in this case uh your worldclass email parser your task is to identify and extract the invoice number in the email below right so you can see I actually start this section with uh this numeric symbol which basically makes this an H1 so it makes it a header and we do this because N&M actually understand markdown formatting so they can actually see okay this is sort of the structure of the prompt right so we usually tend to do this right roll objective your world class email poer right again you generally you want to Hype it up a bit and tell it how good it is right so we use world class or expert Etc then we have the second section which is the instructions where we basically include all the important rules the output formats if we need specific output formats and we correct potential mistakes so you can see the example here instructions again with the numeric symbol to give it an H1 and then we say identify and extract only the invoice number from an email nothing else right so that's rule number one it's important in these systems to always instruct uh these kinds of things in general we a lot of times we're going to pass the output of the language model into an API or into next next model Etc so it's very important that the output is formatted correctly and N&M if you don't say for example there nothing else they tend to start explaining hey uh the invoice number I found is this right now if a language model does that of course the API call is going to give an error we only need a number right so it's very important to instruct these nothing else for example and then the second rule we have here is if no invoice number is available only output not available nothing else and this is what I mean here with correct potential mistakes it's really important in these automation systems to instruct language models what to do if something goes wrong or it doesn't have access to a specific piece of information Etc because first of all our automation will break if uh it doesn't happen and second of all Lang language models are very happy to make up this content if we don't Define what it should do if it doesn't have access to a specific data point right so always important to instruct what to do if something goes wrong right because also this then we can use this not available for example as a filter or a router inside of our scenario to make sure that our automation doesn't break then we have examples examples is one of the most studied principles in prompting especially for these non- reasoning L&M right giving it input and output examples gives a lot of context to these language models what we actually expect the language model to do right and what the output format should actually look like right so the way we do it is we have here the examples with the H1 and then we have an H2 which we do with two numeric symbols example one and example two so in general we try to add in two examples now if it's a very simple task we uh sometimes only do the output right in this case the invoice uh but generally if it's a more complex task you also want to give it an example of an input right so this was the input this is the output this was the input this was the output gives a lot of content on the language model what it has to do with this new task and then the last part is the variable section uh where we basically add in any variable that we might have which in these automation systems again A lot of times we have right so this changes depending on the task in this case the email you will analyze today and then we add in a variable right so that's the uh short prompting framework and you can start most tasks with this short prompting framework test it out see if it works well uh but if we have more complex task or you see your model struggling uh with with the short framework we can use the long structured framework where we basically give even more guardrails and context to the models on what to do to increase reliability right and we generally want to use it for the more complex task right so just extracting an invoice we most likely won't need it right because it's a simple task for NM but generating new content writing a report Etc we actually need it so the framework we use for so the framework we use for these long structured uh prompts uh is the following uh first we have role then we have objective so we basically separate them to go in a little bit more detail in each one and we have context uh instructions examples variables and notes uh so you can see we have some extra ones to give it more guard rails right so we have roll here just just an example uh your worldclass personalized LinkedIn Outreach message assistant with a particular knack for writing highly engaging and personalized LinkedIn Outreach based on the prospect data you're provided with below right so we go a little bit more in depth right also in this in this specific prompt because of course he has to start writing LinkedIn Outreach messages here so uh we really want to give it as much guard rails as possible to get the outcome as good as possible right that's why we use the long one here and we have the objective you can see in the objective I'm I'm a lot more detailed too your goal is to think step by step to the following process to ensure the high quality highest quality outcome right I use this step by step because this is what they call Chain of Thought which might improve the results uh of these prompts a bit uh and then I have uh three points you'll read and analyze the context about me and my company to understand you understand fully who the Outreach messages are written from you'll then read and analyze the prospect data uh which cons consists of a prospect summary and his last LinkedIn post so you understand fully who who the Outreach messages are written to You'll then write a sequence of three engaging personalized LinkedIn Outreach messages based on the data you've analyzed and the detailed instructions here below right then I add in context now this might also improve the performance basically giving more context on the to the L&M on why it's doing this task right so uh just giving it some context on why this task is important uh can also improve the the results of your prompts right so you'll write these messages for me and my company the task is crucial for generating new potential customers to our business then we have instructions again now you can see these instructions are a lot more detailed uh and basically here at the top I give two important instructions first for the output format always use a valid Json in your output just like in examples uh start your answers with and that's a Json the symbol for the Json right curly bracket uh this is usually useful to use when you're trying to get your model to Output Json because sometimes they do it wrong and then we have we have Specific Instructions and rules for each of the messages right your goal on the first outage message is to establish a LinkedIn connection the only goal is making that connection you're going to establish that connection by finding some common ground or common characteristic that is relevant and a valid reason to establish a professional connection so really important for those Outreach messages in my experience to give them lots of card rails because if we give too much Freedom or we don't instruct properly how to write these out Outreach messages we usually get really bad uh copy right so I can you can see I have lots of instructions here for each message specifically too then I give it examples uh right and again it's in the Json format then the variables where I give you more context right the variables for this prompt here's my company's info right and here's information on the prospect right Prospect profile and Prospect past LinkedIn posts and then we add in a last one which is notes and in a note section we can basically double down on important roles um in this case I add in user valid Json right now this note section is very useful especially for these longer prompts because L&M in general the non- reasoning L&M they take um instructions given at the end and at the beginning of the prompt more into account than instructions in the middle of the prom so if he forgets a role here or there's an important role in the middle that he's not following when you're testing it Etc you can add it in a note section and probably you he will uh correct itself pretty quickly so this can be very useful so that's it for the long structured framework and then we have uh prompting reasoning L&M which is very different right because reasoning L&M need a lot less guidance and actually perform way better with very direct prompts they can even start really losing performance when we are too detailed like like in that example I gave before if we try that with a reasoning N&M it would most likely not result in good outcomes especially trying to give reasoning LMS Sops do this first then this then this uh it really starts to struggle in my experience uh because of course they have this reasoning build in so in general with reasoning anms very direct prompts work best right so that's why I have this framework here which is a very short framework we only have the objective we don't even have the role uh where for example write a sentiment analysis report of our company based on our scraped trust pilot page below right instructions where we can again put in some rules if we need them and some output instructions uh so for example provide an overall sentiment summary indicating the percentages of positive neutral and negative reviews and provide the main reasons for positive and negative reviews if sentiment is unclear classifies neutral so just some some rules or some specific context and then we have the context of variables where we give it more context uh in this case the trust pilot page right the scrap trust pilot page but again you can see lot more direct lot more simple we give a lot more freedom to these reasoning L&M and usually uh they perform a lot better like this now when do you choose uh which one uh do you choose a non- reasoning or a reasoning model and which prompt framework uh should you use I just put in a general recommendation or guideline but take this with a grain of salt because it really depends on the specific uh use case you're using it for uh but in general I can sort of of categorize it like this uh again we have the six main types of use cases for L&M in these uh automation Solutions right and I'll give you my general recommendation for each one but again take you with a grain of salt because it depends on the complexity of the specific task but first we have extracting data now in general L&M are really good at extracting data from a large context right so because lnms are really good at this we usually can use uh the non- reasoning models right the cheaper models and we can usually get away with a short uh prompting framework right for example find the url in the Google search results right summarize the text Etc uh then we have classification and categorization again L&M are generally very good at this uh so we can get away with short prompting Frameworks and non- reasoning llms and and also these two tools for example are also now built into make.com in the AI tools which I showed you before making it even even simpler because we don't even have to prompt it then we have uh data transformation still LMS are pretty good at this but uh for some more complex things they they sometimes struggle a bit more so in general we can still use non- reasoning N&M uh for example to convert a text to HTML uh and generally we can get away with a short prompting framework now if we use it for more advanced use cases maybe we want to generate code uh then of course we want to try using uh reasoning models because reasoning models are exceptionally good at code generation then we have evaluation now now generally they're also very good at evaluation for example sentiment analysis or rag retrieval uh evaluation which is a common use case when you're using AI agents for example uh now here we can go with reasoning models uh I tend to see with evaluation or sentiment analysis uh because it's sort of subjective reasoning models can sometimes perform better or we can still use non- reasoning models with long prompting Frameworks in in my experience then we have generation of course where we want an L&M to generate something like these LinkedIn messages or writing a report or writing a personalized email now this is where L&M struggle the most so we want to give them as much guard rails as possible if we're using a non- reasoning model so we want to use the long prompting framework or we can try and use a reasoning model right and with these task we can try both to and see which output you like um but we keep in mind that with reasoning models it tends to be a a lot because we give it less guardrails output consistency will be uh less sort of standardized right because we're giving more freedom to L&M it might result in a better outcome but it also means we might might have sort of diverging types of of answers right well if we use a non- reasoning model with a long structured prompting framework we might have a more sort of reliable and consistent output uh and then last one is decision- making which we mostly use in AI agents right and in AI agents for decision- making because of course it requires a lot of planning and and reasoning to take the right actions to use use the right tools uh I think we will see more and more reasoning models and people will use more and more reasoning models inside of Agents Al when they come become cheaper uh or we can still use uh non- reasoning models but with a long agent prompting framework which is a bit different I have another video on this uh on how to prompt specifically for agents so if you want to check that out make I'll make sure to link it up here and lastly we have prompt chaining which is important to understand and you're going to use a lot in these automation systems uh now why do we use prom chaining because N&M are not great at performing multiple tasks right so we never really want to instruct these N&M modules inside of an automation system to do multiple tasks inside of one prompt so uh for example we don't want to instruct the model to uh extract data points specific data points and make a summary from scraped LinkedIn post and generate a personalized email inside of the same prompt right we want to separate those two into two different AI modules right so each of the prompts and the AI modules has one specific task right the smaller we can keep the task the higher the reliability will become right so I put a line here which I like is if you're finding problems or struggling with consistent outputs in uh your your AI or in your AI module right usually the solution is adding more AI right the solution to the problems of AI is usually more Ai and that means usually breaking it up into multiple AI steps and breaking a larger complex task into multiple steps and we use the outputs uh from the previous module into the next module and that's how we can get the consistently consistency and reliability a lot higher now let's put this all a bit more in practice by building something from scratch uh which I think gives you a good idea of how to start uh building automation systems so uh we can build maybe a lead uh generation system and maybe we can add in uh a personalized email Outreach uh or even a personalized LinkedIn Outreach as I showed you that before so if I go back into make.com we create a new scenario now for lead generation uh what's a really interesting one is in appify we have an Apollo scraper if you don't know Apollo it's basically a platform to find New Leads right in their in their contact information like emails and Linkedin so before I approach this I probably think like what do I need first of all I need the Apollo scraper to uh generate New Leads then uh we can probably uh scrape their LinkedIn to get some more uh data points maybe we can even scrape their last LinkedIn post uh so we can do a personalized Outreach based on their last uh LinkedIn post which can be a bit more personal and more relevant uh and and then we can add it all to maybe a Google sheet right of course this could also be a CRM but let's do Google sheet for now so so here we are in Apollo so first I'll go to appify and show show you uh the scraper so if we go Apollo we have Apollo scraper here scrape up to 50,000 leads right and you can pay you pay $120 $120 for a th000 leads which is a lot cheaper than if you use Apollo yourself so let's just try this one I I already have it inside of my appify uh but as you can see what we need here is the search URL so we basically can put in the search filters in Apollo we add that link and then it will scrape uh that link and it will even scrape multiple pages and here we can also decide the amount of of leads we want to scrape but let's let's keep it at 500 so let's first do a search let's say so let's say for for example we want to scrape some leads for my AI services so here we can uh Define the filter so let's say we want leads from us right we want leads that work in a specific industry let's say uh software when you're doing this in general lead generation you want to be as specific as possible U because otherwise you get lots of of search results and they might not be extremely well suited for your for your business uh company size we can also Define uh let say I think have to do that here in companies first okay so we have software let's say employees between uh 51 to 100 again account location United States so important for this scraper we can only scrape uh lead like people right but we can still add in the field of the companies as you can see they're applied here um and we can say we only want to Target Founders Founders or founder I should say CEOs we can add in co-founder and maybe owner good normally you would want to re uh Define this a bit more specific but here we get 2,100 results so all I do now is just copy this URL and I go to the Apollo scraper here and here we can add in the URL of course you can also make this a variable for example but uh see like so here I I basically add the settings and then the Json here will be updated right so we can copy this Json we go back into make.com and of course now we go to the appify scraper we go run an actor again if you haven't connected right you can uh connect connect your appify count through the API key in in appify just showed before and if you've already used that specific scraper you'll see it appear here if not you can also select it manually here so uh we go with Apollo scraper now in this case this Apollo scraper for example takes quite a while a few minutes because of course it's scraping multiple Pages uh so we want to run it we don't want to run it synchronously because it's going to wait before it ends and sometimes it can time out with these long uh sort of scrap C so we're going to uh choose no we're going to add in Json and you can see we already have the the URL of course you could make this a variable too uh and you could change here the amount Etc but in this case we're just going to use it like this and here this we don't really have to change so we click save and now of course because it's going to run synchronously and you remember if you saw the the earlier example of the appify I used we don't get the results back right away right we have to use another module to get the results back right now of course it will take a few minutes before that mod module before this scraper is actually done right so we have to add in a sleep module so we can add in a sleep module let's say I think the 300 seconds will be enough right and then we choose the um get data set items right and with this module we get back the data of the scrap now we have to add in the data set ID so we have to first run this to get access to this variable right and when you're building uh you constantly have to do that usually to know to to give make context on what variables it can expect from this earlier module that's the only way we can add in these variables in this case let's see maybe we already have it we actually have it here but normally sometimes you have to run it first so make.com knows uh which variables you have access to but here we have the default data set ID so we can use that one data transformation we going go clean and let's just for testing limited to only three results now I'm just GNA of course this is going to fail right but I don't want to wait five minutes in the testing so just put it on one second and you can see it it returned zero bundles because of course it's still running if we look at this one it's still running right so probably in a few minutes uh we'll get back we'll get back the data and normally of course we put this on 300 seconds uh so it will have enough time to actually retrieve the results now we can in the meantime we can work on on the next step so the next step could be what I already know is from this Apollo scraper we usually get back the LinkedIn of uh the lead right so we can add in a LinkedIn scraper here to get some more data on that lead which we can then use of course to personalize our our Outreach uh so for and we also want to add in another scraper that can uh scrape their last LinkedIn post uh so I already know um that that scraper is I don't think it's available on ampliify so we're going to use Rapid API because I know they have a scraper that scrapes uh last LinkedIn post I think it's the LinkedIn data API which one is it let's check I think it's this one so you can see here on the left the options we get right so we can uh get get uh person data which basically scrapes the LinkedIn uh profile data right like the about the the work history Etc we also have an option here of the person's post right so their last post we can also scrape and we can also scrape a company's data right sales Navigator Etc so this is a good a good one so let's just set this one up now you know how we set up these these uh apis so we can see request is post so we go to the HTTP make a request because rapid API doesn't have a native integration ah I'm I'm probably on the wrong one person data yes I am so this this this URL for the headers you can see we have three headers there always a content type with the value application Json and the last address API key now for the body type we always go withraw again application Json and here we posting the request body which we can also find here and you can already see that the request body is the link which of course in our case we're going to make to a variable now as you can see because that module before didn't run yet we don't have access to that variable yet right so first we have to run that one and I think by now our scraper is done so uh we can test this one and what you'll see is if I do run this module only because we've defined this variable we can only run this module of course by defining the variable so when you're testing you just want to do this manually right so you can just go here look at what the uh default data set ID is and then we can run it manually like that uh let me see where it is default data set ID so we paste it in just to be able to test it right and now you can see we get some results back so I defined three right so you can see we got three bundles back three different leads right and you can see we get quite a few data points already the name last name title the LinkedIn profile headline and some of the information so now we can actually map this here as the variable LinkedIn URL and we click parse response and now this one should set uh should be set up now what we can do uh in order to test this one is uh just for the testing purposes we can unlink this just so we don't have to run the whole process again and let the scraper scrape 500 leads again we can just for testing purpos say put this trigger module on this one so we run it from this one now again it's going to ask for that data set ID right which again we're going to just put in manually so if we now click here on run once of course you can see now the variable isn't defined because it's not connected right so it doesn't have access to that variable so we can just for testing purposes put it in manually and afterwards we're going to map it you can see there are three bundles here with three different leads so of course the scraper is going to run three times you can see and now we should have three scraped LinkedIn profiles if we go to data we can see we get all the information uh from the LinkedIn profile of that lead so we get experience education languages everything we need to make a personalized uh LinkedIn Outreach right now we want to add in one more scraper which is the last LinkedIn post to make it even more personalized uh so we're going to add in another uh rap rapid API uh API call right for the LinkedIn post scraper now just copy this one because I know that some of the headers are going to be the same so now I go here to get person post now this is a get request as you can see here so here we have the URL and you can see inside of the URL they put in the the LinkedIn profile that that's going to be scraped where the post are going to be scrapes form right so this we of course want to change into into the variable I think it's until here yes should be until here so here we get LinkedIn URL right so we're adding that variable now see there's some more things defined here which is page is one repost is one comments is one so probably these are filters so let me get back here if we go here in params yeah you can see uh here we can Define if if it filters for only post that are reposts or have comments now we don't necessarily want that so we can you can see that they're optional so we actually uh don't want those and you can see that the URL actually changed right so we don't have that in the URL anymore so I can just take this out right and only page one but we can scrape multiple pages of post too if we want but let's just do one for now we don't want to reference a post they made a long time ago so uh get now let's check the headers two headers in this case and the API key will already be the same right for for the one we already have so you can just change this one and this one's not necessary for this get request and you can see also because it's a get request we don't have a request body so we can leave this empty so now we should be good for this one so again let's test it out and again it's going to run it three times on each of the leads and we can check already if it was successful for here we can see the post so this person only had two posts but you can see we get the last link team post now that's all good now of course we want to generate a personalized Outreach message for LinkedIn based on the data we got uh from the scraped LinkedIn profile and uh LinkedIn post so all we're going to do here is add in an open AI module now if you don't know how to connect open AI um it's quite simple uh you can just go to platform. open.com right there you log into your openi account and once you're in your account uh you could just click here on dashboard I think or on the settings button and there you have an option of API Keys you can create a new key say make.com we create a new key we copy that we go back to make.com right and if we're in the open AI module uh we can go create a completion in here if you're going to add an account right all you have to do is add in your API key there now mine is already connected but that's how you set it up uh now for the modules very quickly you can see we actually have lots of modules available of open AI so we have message and assistant and message an assistant basically means an assistant in openai is basically like an AI agent right so we can uh set up an AI agent inside of uh open a to right uh create a completion is just more a simple prompt basically which in this case is what we need right and we have transform text to structure data which is going to be very useful in these types of automation because you can basically get structured data let's say I want to extract five uh data points from uh that LinkedIn profile and I all want to separate them into separate variables so I can later add them to a Google Sheets uh then then we can just use this and it'll automatically structure the data and we can just Define the variables it has to Output the data into so very useful this is very annoying uh then we have analyze images so it's a vision model right we can generate images we can edit in an image we can create a translation uh which now make.com ai tools also have has and we have can create a transcription from an audio file right moderation generate an audio then we have add files to a vector store so let's say we work with an assistant an agent and we want to give it uh a knowledge base with specific information for example that example I gave before the make.com documentation pages so we can make an agent that has that specific knowledge then uh we could just add that to a vector store and we give give that uh uh to to an assistant so it has that specific knowledge right and that's also related to these batches so that's it um for this case we just need a completion mod uh module now here we can choose the model now in this case we want to give it a lot of guard rails um for writing this personalized message because we're generating content right so we want to give it a lot of guardrails and I prefer uh the non- reasoning models for these kinds of tasks because the reasoning models will have more freedom and less consistency in this sense so I prefer for these types of of of prompts and for these personalized Outreach messages Etc to put in a lot of guard rails and use a non-right reasoning model so we're going to use GPT 40 and what you can see here I'm going to explain this very slow this module in make.com for some reason is we have three options here we have user assistant and developer system now the system uh we can basically use uh for the role prompt right so they sort of separated it uh because it might improve the performance a bit if we just put the r roll prompt here in the system right so let's say we can say uh roll right you you are world class LinkedIn so your world class LinkedIn Outreach message generator by from our company Ben you'll personalize the messages based on the LinkedIn data I've the Le below right just uh the r prompt and then we can add in the user prompt where we put in the entire prompt so let me put in the prompt and I'll get back UNC so I've put in a prompt I adjusted the system prompt to bit your worldclass LinkedIn Outreach message generator from my company Ben your personalize the messages based on LinkedIn data of the lead below right your goal is as my worldclass Outreach message writers to think step by step through the following process to ensure the highest quality outcome now I took this one from the example in the GMA you'll read and analyze the context about me and my company to ensure uh you fully understand who to outreach who the Outreach message is written from you'll then read and analyze the prospect data and his post you then write a personalized LinkedIn Outreach message based on the data you have analyzed then I give it uh some context why is this important you write messages for me and my company this task is crucial for generating new potential customers to our business now I'm very clear in instructions here because these Outreach messages again you want to give it lots of guardrails your goal in the link in the Outreach message to establish a LinkedIn connection the only goal is to making that connection you're going to establish that connection by finding some common ground or common characteristic that is relevant and provides a valid reason now really important to say these right because you've probably experienced this if you don't give them a lot of guard rails they're going to send really salesy Outreach messages right so for example it is vital to my career you'll never pitch our services or ask questions in this message so this by the way is what they call emotional manipulation these models it might sound weird but it actually might improve uh outcomes right there have been some studies uh if there's a relevant LinkedIn post of the prospect that could naturally lead to you sending a connection request that would be a preferred type of personalization for this message so if we can find something interesting on their last LinkedIn post then that is the the best way always follow the tone or voice of the examples below almost mimic them almost always say this for trying to let them follow the tone of voice as much as possible it is vital to my career you keep this message concise and clear you you'll never write more than two sentences you can never use more than 300 characters and then of course I the examples uh so in this case I just have one example but what I usually do is I let it run on a few examples and then if I find a good one I add some more examples in there but instead of wasting lots of time on writing out examples just let the model run and if you like a few add them into the examples because it really helps hone down that tone of voice and then I have the variables right important context on my company and uh and the lead right and then I have the H2 header here with me and my company's info right just some info on what I do and what my company does and then here we of course have the the lead LinkedIn profile data and the leads last LinkedIn post now this where we have to add right so for the last LinkedIn post we can go here on post right and here we find the post text right so we can just add that and here for the leads LinkedIn profile data we have to go to the other module now you can see this is take a collection right now collections you can't pass on directly to a language model right it won't work it's just the way makeon works so you can do this by through another module which is create a string uh which is built-in tool in in make.com or you can just separate the the values you want to pass over here separately so let's say we're going to pass over the name we're going to do the headline the let's say maybe you can do something with the country experiences this could be interesting title education add maybe we can add in some scales uh maybe let's see I forget something important let's just keep it at this and see what happens right we can add in some more data points but uh let's just add in this and see what model does and then last you have the notes section where I double down on that tone of voice now again if you see something going wrong it's great in general great to add this to the notes right when you're testing so let's try this out by the way you do have some more options here right you can also add in images of course and you can also do the response format so you can have this structured output directly in this complete completion model too so we can sort of force it to Output it into adjacent object now this case not not very necessary you can also uh Define the max completion tokens right the maximum uh number of tokens to use in the completion in the output right uh so we can actually Define that for this one for example because we know we can't pass more than 300 words so you could play around with that then we have the temperature uh and some some other options that you won't really need in practice so uh let's just run it let's try see what happens again I won't connect the whole thing just to check out what's going to happen here we got the first message hello Chris congratulations on securing your series a uh exciting times for win reality and the future sports training in VR would love to connect so pretty good pretty personalized it didn't really relate it back to me or something but it's also because it's very unrelated uh not bad I'd say let's see about the others hey uh adicha I saw your post about uh shooting your podcast must have been a great experience as a fellow founder navigating the AI space I'd love to connect pretty good and then we have the third one hello Bob I saw your post about bringing RTX 509 to set it for AI workloads very exciting as someone passionate about AI advancements I'd love to connect great it's uh doing a pretty good job I think so I could add this one then as an example as an extra example because we give it more context on on what output we want right so let's say it's pretty good now uh what we can do uh first of all of course maybe save this data right in a database or in a CRM now let's say uh we're going to use just Google Sheets for now uh so what I'll do is I'll first create a Google Sheets with all the data points we want to save and we can just go like okay name we want the name we want the last name want the email uh we want the LinkedIn profile uh we want the company name company URL and maybe I think we also get the company LinkedIn URL of course you can make this this workflow much more complex right we can add lots more we can personalize emails we can personalize multiple messages we can even start scraping the company data uh to become even more person personalized Etc but let's say now we do the LinkedIn Outreach message we add in the sheet two and we call it lead LinkedIn right now if we go back to make.com so we can just add in Google Sheets here and we can click add a row right now my account's already connected but if it isn't you can just log to your Google account right and the nice thing is we already have uh your spreadsheets in your account automatically loaded here so you can see we have leads LinkedIn here and we're going to select the sheet name then you select if the table contains headers or not and you can see the values are automatically shown here so now I can just map them and the name we already got from uh appify right so we have first name last name right email email LinkedIn profile company name must get from LinkedIn to we get we get it from okay here from so we can in here reality name URL here and URL and we can add L message and of course you can add lots more data points because we got also got a lot lot of new data points from these LinkedIn profiles uh but just for the example let's put it like this and we run again R it again and if we go back to the sheets right now you can see right we just get it filled out of course you get a lot you can get a lot more fancy here right we can do a lot more we can extract a lot more data and enrich it in a database uh but you get the idea now of course we can to completely uh do the whole process we would add in uh this and of course adding a delay here you can see the schedule was automatically here and now we can literally run this uh every day for example to scrape new leads and add them to Google sheet now you can actually send this LinkedIn Outreach message directly to uh you'd use a service that's called unial uh now that will cost you I think maybe $40 a month I don't have that account right now so I can't show you but uh here you can basically add in an API to send LinkedIn messages so you could add that into your flow here and actually send out LinkedIn requests or or or messages so that's it I also make sure to share the the template of this uh blueprint uh together with the resources of this video now let's go over the last part of this video which are some more advanced skills and techniques you should probably learn in make.com especially if you start building out more automations uh so let me go back to the presentation so what I'm going to cover quickly are functions right T text text function General functions uh and some other functions and text parsers now functions in make.com are basically built-in ways to uh work with data or do something with data now the main use cases for these are usually either to filter some data uh to transform data for example arrays Etc uh to clean up data uh for example apis API calls usually don't accept are not very flexible right so they don't accept special symbols they don't accept new lines uh special character vors in in in letters things like that so A lot of times we have to clean up the data a bit before we can pass it onto the API call and text functions can be very useful uh for this uh we can also work with conditions in these functions but let me show you very quickly so I'm just going to add one here so we can we can show you so I'll just put in the set variable so here at the top you can see on the left side we always have access to our Vari variables right from the previous modules but here we have a few other options and here we basically have our make.com function right so here we have General functions math functions text and binary functions date and time and array functions now in practice you're mostly going to use really the text uh some maybe sometimes General functions and date and maybe sometimes array so let me go over the important ones very quickly so how does this work let's just set an example variable name so what we can do here is if we select this you can see that the explanation will be in the tool tip uh but basically can just select this for example this length one checks the length of a specific uh string right or a variable of course we can pass in a variable here too so let's say we add in uh that variable results right to actually check let's say that uh LinkedIn only accepts messages of Maximum 300 characters so for example we can use this length to actually check uh how long this message is and maybe we can then decide based on if it's too long we can put in a filter to actually not send it out to the API for example right to avoid an error or we can uh reprocess it until we actually have less than 300 and then send it out right so that could be for example use case of this so if I run this of course I have to define the variable because I don't want to run the whole flow again so let's just say like hi just the just as an example you can see that we get back the amount of characters right and of course now we get this in a variable and then we can add in a filter for example right uh so let's say we can add in a filter here with that condition right so that could be a use case now let me go over all of them very quickly so let's say here in the text function we have lower which basically makes uh makes all uppercase or capitalized letters into lowercase we have the the the other way around right lower case into capitalized uh start case Etc replace you for example we can replace a specific word inside of a string here so uh let's say hi Ben here in the second one we Define the word we want to replace right and then here we can Define uh the word we want to replace it for right so that's as you can see now it's hello B right sometimes you might use this one but let me go over the more more practical ones uh trim you might sometimes use because again like I said API calls in request bodies don't accept lots of empty spaces or new lines Etc and what trim does as you can see you remove space characters at the start or the end of a text right so let's say we have to pass on a clean text that has spaces uh before and at the end and therefore our API call gives an error we can just right so let's say we have two spaces here we just run this right now you can see we don't have any spaces right so this trim trim function you might use sometimes uh then we have upper which again makes all letters in uppercase substring you also might use sometimes because sometimes API calls have limits of the amount of characters we can pass on through the API call uh so let's say we are scraping a website and we get I don't know uh 20,000 characters back uh but we can only pass in 5,000 um characters into the API call we don't really need the end of the text then we can use this substring and here we can basically Define uh let's say we do a very short one right now but here we can Define which of the the characters we want uh to retrieve back so we can basically limit it let's say we only want from zero to the third character and in practice you're probably going to use this more like 5,000 but and pass in a variable here but just as an example you can see if I run this now we only get the first three characters back right so substring you might use sometimes for those API calls then we have um upper two string uh this this could be useful also you can basic Bally convert any other value to a string so let's say you have a number function but the next API call uh requires text field with the number and you can just convert that number into a string right or even an array or uh maybe a Bolan right so that's what this one does then we have um maybe maybe this one the split can be useful right with splits we can create arrays uh from strings basically so uh what we can say is like let's say we have three websites we get back from API call but we want to process each website separately to scrape them right so we can go website one comma website 2 comma website three right and here we Define the symbol we want to separate it from right so in this case we've separated with comma so we just type in the comma and it will know where to split the array from so if I run this you can see now we get an array here with the three websites right and then of course we could use an iterator right to Loop over each of those separately to scrape them separately right so you might use that one sometimes uh then we have contains maybe you use uh contains what it does is it verifies if a specific um string actually contains a certain word right and there and it brings back a bon right true or false so again we can check if an email is actually valid by checking if it includes uh an add sign for example and if not uh we can get a false statement back where which we can then use as a condition right to not uh use the send email module which will give us an error if we don't have a valid email right so might use that one sometimes then we have uh General functions now General functions not very useful this one get you might use sometimes with get you can basically get a specific value from an array uh so let's say I have that example I'll just just going to add this here just so we can test this we want to get one specific value from that array for example that scrap LinkedIn we only are interested in job title or a specific data point there then we can add this uh to get that specific data point so set variable so we go get we have in the array right and we want the specific value and we can just choose the the one we want so let's say we want the second one if we run this what you can see we only we only get the second string now right uh that's it for get then we have uh let's see what else we have then we have if where we can put in a a simple condition and if the condition is met we can uh output one specific value and if not another specific value so if you see the example there if one is one it will uh output a sorry and if uh one is not one it will output B right and you can use these types of conditions here is is not equal to and or or right and we can also use these true or false here now if empty you might sometimes use so if a string is empty return this right because again sometimes if we uh send over empty strings over over to an API call it'll give us errors so let's say a scraped website didn't work uh then we can at least say not available or something like that if uh let's say if if a specific result right is empty then uh output not available right that's what it will do right now of course again we can use that as a condition that's it really for the general function then math functions speaks for itself we can do simple math here right we could just use these Plus or times Etc and it will do math right we have some others but I never really use it in practice then we have dates now in dates you do use it sometimes because again API calls sometimes ask for timestamps uh so you can get a specific time stamp here or you can get the specific date of the day which is pretty useful sometimes so if you click on now you basically get the date of the day for right now right so as you can see right you get you get the date right and you can also uh then do a perform a function on it let's say for example I'm scheduling a a task in my to-do list and I want to have a due date in three days uh then I can make a function here where I add days to the date right so add days we select the now and then we just add three right and now it's basically added three days to the to the today's day right so can be very useful and also make.com already has sort of the right format uh to pass into API calls normally and we can do some other things like format date to for example change the format date from European dates to us dates things like this uh then we have array functions with array uh what could be useful is the join array right so basically takes all the array uh data into a string uh and I want can be useful so for example if we want to get this into sorry into an A String let we run this right you see we get we get it in a string instead of an array right so it could be useful um then we have length same thing counts the amount of of uh values in the array we can use merge right that merges two or more arrays into one array uh contains verifies if a array contains the value Now map is one you actually sometimes use so because basically what you can do with map map is uh pick specific values inside of an array to uh only return back those right because for example in that LinkedIn data we get lots of information that is not that useful for us uh so we can then pick the specific ones right in there as you can see here can pick all the specific values we want to bring back and then it filters out that that data basically uh you have another one that you might sometimes use which is flatten and what FL flatten does it basically sometimes you have an array inside of an array and what uh this module does is it simplifies it so it takes that array inside of an array and puts it into one original uh array right so it sort of simplifies the data B uh that's it I think really what you should know for functions now again it's you have to play around with this to to get a feeling for this but it definitely but let's get to the last part of this video I know it's been a very long one but after if you still watching this you've literally learned almost anything you need to know to build any automation on make.com uh so the last one is text parsers which we sometimes use and specifically I'm going to talk about uh the match Elements which we use regx for or regular expression right the other text bares we've already seen a bit I can show you very quickly we do have some other text far text farers beside that uh so we have the HTML ones right I showed you the HTML to text which in practice you're going to use most by the way there's also a function to convert HTML to text uh which might be more efficient sometimes to use a function instead of this text parer module uh because functions don't um cost operations right while uh adding in a text parer of course will charge you another operations but the one I'm going to talk about is the match pattern one and the match pattern basically what it does is it can help you match specific patterns over context or over a text and it can help you with extracting uh data it can help you identify specific uh text or or strings inside of a larger context it can replace it can clean up text or it can uh extract specific data like emails numbers dates uh or any format you're looking for in a larger context now it can be very useful when you have a specific sort of output you get from an API call and you're always looking for a specific uh format or specific data point inside of that text now with AI it's become a lot easier for for for everyone to do this actually because we can just pass in text to an AI instruct what to extract and uh we have it as an output but traditionally regx and regular Expressions were used a lot for this and it is still a more efficient way to extract this especially if we have a very consistent output from an API and we always have to extract a similar thing or similar data point from that text then we can use uh these these match elements with regular expression to extract the data without using AI tokens right so of course it is going to be more efficient to use a text parcel like this so let me show you an example because in the original automation of the competitor tracker we use the text parser right uh to with a match pattern right so as you can see here here we have to add in the pattern right the regular expression again I'm not a developer so I have no idea how to actually do this but the good thing thing is we now have ai to make these regular expressions for us right so uh and here we just passed in the text now in this case uh from this RSS module we got uh let's skip here right we got a URL back right uh with the new video right now to scrape the transcript we don't we can't pass in the API the entire link we only want to pass in this video ID which is this last part right and because every link is going to be similar and we only want to extract this part we can use a text parser for this right so we might even want to be able to use a function here uh where we basically replace uh this part or take out this part right and only have the last part but in this case uh we're using a text parser so and what you can see here at the end we only get right that video ID which we then pass into the API call here right so how does this work how do we set this up so again best way is to do this simply with AI so what we do is we just pass in right that URL to uh say chat GPT now again the the reasoning models are usually the best at this but uh you can just say something like please write me uh regular expression which I'm going to use in make.com in the text parer match pattern I need a regular expression that extracts only the video ID of a URL right here's an example and the video ID is we adding that video idea that's it and you see we we just get the the regular expression right alternatively you can also do this but let's say we copy this you can see it's actually different than the one we have here but it should still work cuz there's multiple ways to write these these patterns right so if we now click save and we run it again right you can see that it did it correctly right and it does it for for all the ones right so that's it can be pretty pretty useful um and also to save up save cost on on a open AI or or any other AI module because of course you could do this by adding in an open AI module here and extracting uh extracting the specific video URL but you can use this for for other use cases too for scraping is also a common use case also to clean up data for example what I said these new lines we can just instruct the model take instruct our our GPT uh extra you know take out write a regular expression that takes out all special characters all new lines all white spaces uh any accents uh capital letters we can say anything and it will write us the regular expression which and then we can pass on that that data that scrape data into the text sper which will clean it up again especially if we have you know let's say a a text with 10,000 characters of course we can let AI do it but it's going to be a lot more coste efficient if you let a text parer do it so very useful to know that's it for the entire make.com tutorial if you're still with me kudos to you and thank you so much for sticking with me uh if you like this video I highly appreciate a like and a subscribe and uh if you want to learn more and learn more about how to build AI automation systems uh in our community we have lots of templates available we have an active community of people building and building businesses in the AI space uh we're also doing co-build sessions for if you're a beginner learning how to build these systems from scratch so if you're interested in in something like this and starting your own AI business uh I would love to see you there and uh thank you so much again and hope to see you in the next one bye 